{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfkFaZFUq1Jw",
        "outputId": "0ea9bac8-2832-453d-b897-f0536db2625b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from rice.csv...\n",
            "Original data shape: (106, 6)\n",
            "Original columns: ['Commodity', 'Market', '1KG Price', '1Q Price', '1Q Max - Min', 'Date']\n",
            "\n",
            "First few rows of original data:\n",
            "                        Commodity      Market 1KG Price    1Q Price  \\\n",
            "0                   Rice - Coarse    Kalburgi   ₹ 43.00  ₹ 4,300.00   \n",
            "1                     Rice - Fine    Kalburgi   ₹ 56.00  ₹ 5,600.00   \n",
            "2  Rice - CR 1009 (Coarse) Boiled  Kalagategi   ₹ 29.00  ₹ 2,900.00   \n",
            "3              Rice - Broken Rice    Kalburgi   ₹ 35.00  ₹ 3,500.00   \n",
            "4              Rice - Sarbati Raw   Somvarpet   ₹ 27.00  ₹ 2,700.00   \n",
            "\n",
            "          1Q Max - Min        Date  \n",
            "0  ₹ 4700 - ₹ 3,700.00  23/10/2025  \n",
            "1  ₹ 6300 - ₹ 4,700.00  23/10/2025  \n",
            "2  ₹ 2900 - ₹ 2,900.00  23/10/2025  \n",
            "3  ₹ 4400 - ₹ 2,900.00  23/10/2025  \n",
            "4  ₹ 2700 - ₹ 2,700.00  23/10/2025  \n",
            "\n",
            "Processing data...\n",
            "\n",
            "✓ Processing completed!\n",
            "Processed data shape: (106, 29)\n",
            "\n",
            "All columns (29):\n",
            "  1. Date\n",
            "  2. Commodity\n",
            "  3. Season\n",
            "  4. Price_1KG\n",
            "  5. Price_1Q\n",
            "  6. Price_Max\n",
            "  7. Price_Min\n",
            "  8. Price_Range\n",
            "  9. Price_1KG_Lag_1\n",
            "  10. Price_1KG_Lag_7\n",
            "  11. Price_1KG_Lag_14\n",
            "  12. Price_1KG_Lag_30\n",
            "  13. Price_1KG_RollingAvg_7\n",
            "  14. Price_1KG_RollingAvg_14\n",
            "  15. Price_1KG_RollingAvg_30\n",
            "  16. Price_1KG_RollingStd_7\n",
            "  17. Price_1KG_RollingStd_14\n",
            "  18. Price_1KG_RollingStd_30\n",
            "  19. Price_1KG_Change\n",
            "  20. Price_1KG_PctChange\n",
            "  21. Day\n",
            "  22. Month\n",
            "  23. Year\n",
            "  24. DayOfWeek\n",
            "  25. Quarter\n",
            "  26. WeekOfYear\n",
            "  27. Price_Range_RollingAvg_7\n",
            "  28. Price_1KG_EMA_7\n",
            "  29. Price_1KG_EMA_30\n",
            "\n",
            "================================================================================\n",
            "SAMPLE OF PROCESSED DATA (First 5 rows)\n",
            "================================================================================\n",
            "        Date Commodity  Season  Price_1KG  Price_1Q  Price_Max  Price_Min  Price_Range  Price_1KG_Lag_1  Price_1KG_Lag_7  Price_1KG_Lag_14  Price_1KG_Lag_30  Price_1KG_RollingAvg_7  Price_1KG_RollingAvg_14  Price_1KG_RollingAvg_30  Price_1KG_RollingStd_7  Price_1KG_RollingStd_14  Price_1KG_RollingStd_30  Price_1KG_Change  Price_1KG_PctChange  Day  Month  Year  DayOfWeek  Quarter  WeekOfYear  Price_Range_RollingAvg_7  Price_1KG_EMA_7  Price_1KG_EMA_30\n",
            "0 2022-09-27      Rice  Kharif       24.0    2400.0     2600.0     2200.0        400.0              NaN              NaN               NaN               NaN                   24.00                    24.00                    24.00                     NaN                      NaN                      NaN               NaN                  NaN   27      9  2022          1        3          39                400.000000        24.000000         24.000000\n",
            "1 2022-10-14      Rice  Kharif       20.0    2000.0     2000.0     2000.0          0.0             24.0              NaN               NaN               NaN                   22.00                    22.00                    22.00                2.828427                 2.828427                 2.828427              -4.0            -0.166667   14     10  2022          4        4          41                200.000000        23.000000         23.741935\n",
            "2 2022-10-21      Rice  Kharif       20.8    2080.0     2080.0     2080.0          0.0             20.0              NaN               NaN               NaN                   21.60                    21.60                    21.60                2.116601                 2.116601                 2.116601               0.8             0.040000   21     10  2022          4        4          42                133.333333        22.450000         23.552133\n",
            "3 2022-10-27      Rice  Kharif       20.0    2000.0     2000.0     2000.0          0.0             20.8              NaN               NaN               NaN                   21.20                    21.20                    21.20                1.904381                 1.904381                 1.904381              -0.8            -0.038462   27     10  2022          3        4          43                100.000000        21.837500         23.322963\n",
            "4 2022-11-22      Rice    Rabi       20.0    2000.0     3000.0     1800.0       1200.0             20.0              NaN               NaN               NaN                   20.96                    20.96                    20.96                1.734359                 1.734359                 1.734359               0.0             0.000000   22     11  2022          1        4          47                320.000000        21.378125         23.108579\n",
            "\n",
            "================================================================================\n",
            "DATA STATISTICS\n",
            "================================================================================\n",
            "        Price_1KG      Price_1Q     Price_Max    Price_Min  Price_Range\n",
            "count  106.000000    106.000000    106.000000   106.000000   106.000000\n",
            "mean    37.637453   3763.745283   4171.801887  3426.839623   744.962264\n",
            "std     15.066362   1506.636247   1860.590205  1279.400620  1141.858818\n",
            "min     17.500000   1750.000000   1800.000000  1700.000000     0.000000\n",
            "25%     26.000000   2600.000000   2800.000000  2400.000000     0.000000\n",
            "50%     32.965000   3296.500000   3663.500000  3000.000000   356.000000\n",
            "75%     44.750000   4475.000000   5150.000000  4050.000000  1037.500000\n",
            "max    102.000000  10200.000000  12500.000000  8000.000000  8000.000000\n",
            "\n",
            "================================================================================\n",
            "SEASON DISTRIBUTION\n",
            "================================================================================\n",
            "Season\n",
            "Kharif    64\n",
            "Rabi      42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Kharif: 64 records (60.4%)\n",
            "Rabi: 42 records (39.6%)\n",
            "\n",
            "================================================================================\n",
            "DATE RANGE\n",
            "================================================================================\n",
            "Earliest date: 27/09/2022\n",
            "Latest date: 23/10/2025\n",
            "Total days covered: 1122 days\n",
            "\n",
            "================================================================================\n",
            "✓ SUCCESS! Processed data saved to 'rice_prices_processed.csv'\n",
            "Total records processed: 106\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def determine_season(date):\n",
        "    \"\"\"\n",
        "    Determine crop season based on month\n",
        "    Kharif: April (4) to October (10)\n",
        "    Rabi: November (11) to May (5)\n",
        "    \"\"\"\n",
        "    month = date.month\n",
        "    if 4 <= month <= 10:\n",
        "        return 'Kharif'\n",
        "    else:\n",
        "        return 'Rabi'\n",
        "\n",
        "def remove_rupee_symbol(value):\n",
        "    \"\"\"Remove rupee symbol and commas, convert to float\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    if isinstance(value, (int, float)):\n",
        "        return float(value)\n",
        "    # Remove ₹ symbol, commas, and whitespace\n",
        "    cleaned = re.sub(r'[₹,\\s]', '', str(value))\n",
        "    try:\n",
        "        return float(cleaned)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def parse_max_min(max_min_str):\n",
        "    \"\"\"Parse 'Max - Min' column into separate max and min values\"\"\"\n",
        "    if pd.isna(max_min_str):\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        # Split by '-' and clean each part\n",
        "        parts = str(max_min_str).split('-')\n",
        "        if len(parts) == 2:\n",
        "            max_val = remove_rupee_symbol(parts[0].strip())\n",
        "            min_val = remove_rupee_symbol(parts[1].strip())\n",
        "            return max_val, min_val\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return np.nan, np.nan\n",
        "\n",
        "def standardize_commodity(commodity):\n",
        "    \"\"\"Standardize commodity name to 'Rice'\"\"\"\n",
        "    return 'Rice'\n",
        "\n",
        "def preprocess_rice_data(df):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for rice price data\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Standardize commodity name to 'Rice'\n",
        "    df_processed['Commodity'] = df_processed['Commodity'].apply(standardize_commodity)\n",
        "\n",
        "    # 2. Drop Market column\n",
        "    df_processed = df_processed.drop('Market', axis=1)\n",
        "\n",
        "    # 3. Parse and separate Max-Min column\n",
        "    df_processed[['Price_Max', 'Price_Min']] = df_processed['1Q Max - Min'].apply(\n",
        "        lambda x: pd.Series(parse_max_min(x))\n",
        "    )\n",
        "    df_processed = df_processed.drop('1Q Max - Min', axis=1)\n",
        "\n",
        "    # 4. Remove rupee symbols from price columns\n",
        "    df_processed['Price_1KG'] = df_processed['1KG Price'].apply(remove_rupee_symbol)\n",
        "    df_processed['Price_1Q'] = df_processed['1Q Price'].apply(remove_rupee_symbol)\n",
        "    df_processed = df_processed.drop(['1KG Price', '1Q Price'], axis=1)\n",
        "\n",
        "    # 5. Convert Date column to datetime\n",
        "    df_processed['Date'] = pd.to_datetime(df_processed['Date'], format='%d/%m/%Y')\n",
        "\n",
        "    # 6. Add Season column\n",
        "    df_processed['Season'] = df_processed['Date'].apply(determine_season)\n",
        "\n",
        "    # Sort by date for time series features\n",
        "    df_processed = df_processed.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # 7. Feature Engineering - Lag features\n",
        "    # Create lag features for Price_1KG (1, 7, 14, 30 days)\n",
        "    for lag in [1, 7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_Lag_{lag}'] = df_processed['Price_1KG'].shift(lag)\n",
        "\n",
        "    # 8. Rolling averages (7, 14, 30 days)\n",
        "    for window in [7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_RollingAvg_{window}'] = (\n",
        "            df_processed['Price_1KG'].rolling(window=window, min_periods=1).mean()\n",
        "        )\n",
        "\n",
        "    # 9. Rolling standard deviation (volatility measure)\n",
        "    for window in [7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_RollingStd_{window}'] = (\n",
        "            df_processed['Price_1KG'].rolling(window=window, min_periods=1).std()\n",
        "        )\n",
        "\n",
        "    # 10. Price change features\n",
        "    df_processed['Price_1KG_Change'] = df_processed['Price_1KG'].diff()\n",
        "    df_processed['Price_1KG_PctChange'] = df_processed['Price_1KG'].pct_change()\n",
        "\n",
        "    # 11. Price range (Max - Min)\n",
        "    df_processed['Price_Range'] = df_processed['Price_Max'] - df_processed['Price_Min']\n",
        "\n",
        "    # 12. Time-based features\n",
        "    df_processed['Day'] = df_processed['Date'].dt.day\n",
        "    df_processed['Month'] = df_processed['Date'].dt.month\n",
        "    df_processed['Year'] = df_processed['Date'].dt.year\n",
        "    df_processed['DayOfWeek'] = df_processed['Date'].dt.dayofweek\n",
        "    df_processed['Quarter'] = df_processed['Date'].dt.quarter\n",
        "    df_processed['WeekOfYear'] = df_processed['Date'].dt.isocalendar().week\n",
        "\n",
        "    # 13. Moving average of price range\n",
        "    df_processed['Price_Range_RollingAvg_7'] = (\n",
        "        df_processed['Price_Range'].rolling(window=7, min_periods=1).mean()\n",
        "    )\n",
        "\n",
        "    # 14. Exponential moving average\n",
        "    df_processed['Price_1KG_EMA_7'] = (\n",
        "        df_processed['Price_1KG'].ewm(span=7, adjust=False).mean()\n",
        "    )\n",
        "    df_processed['Price_1KG_EMA_30'] = (\n",
        "        df_processed['Price_1KG'].ewm(span=30, adjust=False).mean()\n",
        "    )\n",
        "\n",
        "    # Reorder columns for better readability\n",
        "    cols = ['Date', 'Commodity', 'Season', 'Price_1KG', 'Price_1Q', 'Price_Max', 'Price_Min', 'Price_Range']\n",
        "    other_cols = [col for col in df_processed.columns if col not in cols]\n",
        "    df_processed = df_processed[cols + other_cols]\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Read from CSV file\n",
        "    input_file = 'rice.csv'\n",
        "    output_file = 'rice_prices_processed.csv'\n",
        "\n",
        "    try:\n",
        "        print(f\"Reading data from {input_file}...\")\n",
        "\n",
        "        # Read CSV, skipping the first row (header text) and last row (footer)\n",
        "        df = pd.read_csv(input_file, skiprows=1)\n",
        "\n",
        "        # Remove any rows that contain 'Downloaded from' or empty rows\n",
        "        df = df[~df['Commodity'].astype(str).str.contains('Downloaded|^$', na=False)]\n",
        "\n",
        "        # Remove any completely empty rows\n",
        "        df = df.dropna(how='all')\n",
        "\n",
        "        print(f\"Original data shape: {df.shape}\")\n",
        "        print(f\"Original columns: {df.columns.tolist()}\")\n",
        "        print(\"\\nFirst few rows of original data:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Process the data\n",
        "        print(\"\\nProcessing data...\")\n",
        "        df_processed = preprocess_rice_data(df)\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\n✓ Processing completed!\")\n",
        "        print(f\"Processed data shape: {df_processed.shape}\")\n",
        "        print(f\"\\nAll columns ({len(df_processed.columns)}):\")\n",
        "        for i, col in enumerate(df_processed.columns, 1):\n",
        "            print(f\"  {i}. {col}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SAMPLE OF PROCESSED DATA (First 5 rows)\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_processed.head().to_string())\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATA STATISTICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_processed[['Price_1KG', 'Price_1Q', 'Price_Max', 'Price_Min', 'Price_Range']].describe())\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASON DISTRIBUTION\")\n",
        "        print(\"=\"*80)\n",
        "        season_counts = df_processed['Season'].value_counts()\n",
        "        print(season_counts)\n",
        "        print(f\"\\nKharif: {season_counts.get('Kharif', 0)} records ({season_counts.get('Kharif', 0)/len(df_processed)*100:.1f}%)\")\n",
        "        print(f\"Rabi: {season_counts.get('Rabi', 0)} records ({season_counts.get('Rabi', 0)/len(df_processed)*100:.1f}%)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATE RANGE\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Earliest date: {df_processed['Date'].min().strftime('%d/%m/%Y')}\")\n",
        "        print(f\"Latest date: {df_processed['Date'].max().strftime('%d/%m/%Y')}\")\n",
        "        print(f\"Total days covered: {(df_processed['Date'].max() - df_processed['Date'].min()).days} days\")\n",
        "\n",
        "        # Save to CSV\n",
        "        df_processed.to_csv(output_file, index=False)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"✓ SUCCESS! Processed data saved to '{output_file}'\")\n",
        "        print(f\"Total records processed: {len(df_processed)}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n✗ Error: File '{input_file}' not found.\")\n",
        "        print(\"Please ensure the CSV file is in the same directory as this script.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error processing data: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def determine_season(date):\n",
        "    \"\"\"\n",
        "    Determine crop season based on month\n",
        "    Kharif: April (4) to October (10)\n",
        "    Rabi: November (11) to May (5)\n",
        "    \"\"\"\n",
        "    month = date.month\n",
        "    if 4 <= month <= 10:\n",
        "        return 'Kharif'\n",
        "    else:\n",
        "        return 'Rabi'\n",
        "\n",
        "def remove_rupee_symbol(value):\n",
        "    \"\"\"Remove rupee symbol and commas, convert to float\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    if isinstance(value, (int, float)):\n",
        "        return float(value)\n",
        "    # Remove ₹ symbol, commas, and whitespace\n",
        "    cleaned = re.sub(r'[₹,\\s]', '', str(value))\n",
        "    try:\n",
        "        return float(cleaned)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def parse_max_min(max_min_str):\n",
        "    \"\"\"Parse 'Max - Min' column into separate max and min values\"\"\"\n",
        "    if pd.isna(max_min_str):\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        # Split by '-' and clean each part\n",
        "        parts = str(max_min_str).split('-')\n",
        "        if len(parts) == 2:\n",
        "            max_val = remove_rupee_symbol(parts[0].strip())\n",
        "            min_val = remove_rupee_symbol(parts[1].strip())\n",
        "            return max_val, min_val\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return np.nan, np.nan\n",
        "\n",
        "def standardize_commodity(commodity):\n",
        "    \"\"\"Standardize commodity name to 'Rice'\"\"\"\n",
        "    return 'Tur'\n",
        "\n",
        "def preprocess_rice_data(df):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for rice price data\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Standardize commodity name to 'Rice'\n",
        "    df_processed['Commodity'] = df_processed['Commodity'].apply(standardize_commodity)\n",
        "\n",
        "    # 2. Drop Market column\n",
        "    df_processed = df_processed.drop('Market', axis=1)\n",
        "\n",
        "    # 3. Parse and separate Max-Min column\n",
        "    df_processed[['Price_Max', 'Price_Min']] = df_processed['1Q Max - Min'].apply(\n",
        "        lambda x: pd.Series(parse_max_min(x))\n",
        "    )\n",
        "    df_processed = df_processed.drop('1Q Max - Min', axis=1)\n",
        "\n",
        "    # 4. Remove rupee symbols from price columns\n",
        "    df_processed['Price_1KG'] = df_processed['1KG Price'].apply(remove_rupee_symbol)\n",
        "    df_processed['Price_1Q'] = df_processed['1Q Price'].apply(remove_rupee_symbol)\n",
        "    df_processed = df_processed.drop(['1KG Price', '1Q Price'], axis=1)\n",
        "\n",
        "    # 5. Convert Date column to datetime\n",
        "    df_processed['Date'] = pd.to_datetime(df_processed['Date'], format='%d/%m/%Y')\n",
        "\n",
        "    # 6. Add Season column\n",
        "    df_processed['Season'] = df_processed['Date'].apply(determine_season)\n",
        "\n",
        "    # Sort by date for time series features\n",
        "    df_processed = df_processed.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # 7. Feature Engineering - Lag features\n",
        "    # Create lag features for Price_1KG (1, 7, 14, 30 days)\n",
        "    for lag in [1, 7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_Lag_{lag}'] = df_processed['Price_1KG'].shift(lag)\n",
        "\n",
        "    # 8. Rolling averages (7, 14, 30 days)\n",
        "    for window in [7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_RollingAvg_{window}'] = (\n",
        "            df_processed['Price_1KG'].rolling(window=window, min_periods=1).mean()\n",
        "        )\n",
        "\n",
        "    # 9. Rolling standard deviation (volatility measure)\n",
        "    for window in [7, 14, 30]:\n",
        "        df_processed[f'Price_1KG_RollingStd_{window}'] = (\n",
        "            df_processed['Price_1KG'].rolling(window=window, min_periods=1).std()\n",
        "        )\n",
        "\n",
        "    # 10. Price change features\n",
        "    df_processed['Price_1KG_Change'] = df_processed['Price_1KG'].diff()\n",
        "    df_processed['Price_1KG_PctChange'] = df_processed['Price_1KG'].pct_change()\n",
        "\n",
        "    # 11. Price range (Max - Min)\n",
        "    df_processed['Price_Range'] = df_processed['Price_Max'] - df_processed['Price_Min']\n",
        "\n",
        "    # 12. Time-based features\n",
        "    df_processed['Day'] = df_processed['Date'].dt.day\n",
        "    df_processed['Month'] = df_processed['Date'].dt.month\n",
        "    df_processed['Year'] = df_processed['Date'].dt.year\n",
        "    df_processed['DayOfWeek'] = df_processed['Date'].dt.dayofweek\n",
        "    df_processed['Quarter'] = df_processed['Date'].dt.quarter\n",
        "    df_processed['WeekOfYear'] = df_processed['Date'].dt.isocalendar().week\n",
        "\n",
        "    # 13. Moving average of price range\n",
        "    df_processed['Price_Range_RollingAvg_7'] = (\n",
        "        df_processed['Price_Range'].rolling(window=7, min_periods=1).mean()\n",
        "    )\n",
        "\n",
        "    # 14. Exponential moving average\n",
        "    df_processed['Price_1KG_EMA_7'] = (\n",
        "        df_processed['Price_1KG'].ewm(span=7, adjust=False).mean()\n",
        "    )\n",
        "    df_processed['Price_1KG_EMA_30'] = (\n",
        "        df_processed['Price_1KG'].ewm(span=30, adjust=False).mean()\n",
        "    )\n",
        "\n",
        "    # Reorder columns for better readability\n",
        "    cols = ['Date', 'Commodity', 'Season', 'Price_1KG', 'Price_1Q', 'Price_Max', 'Price_Min', 'Price_Range']\n",
        "    other_cols = [col for col in df_processed.columns if col not in cols]\n",
        "    df_processed = df_processed[cols + other_cols]\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Read from CSV file\n",
        "    input_file = 'arhar_tur_whole.csv'\n",
        "    output_file = 'tur_prices_processed.csv'\n",
        "\n",
        "    try:\n",
        "        print(f\"Reading data from {input_file}...\")\n",
        "\n",
        "        # Read CSV, skipping the first row (header text) and last row (footer)\n",
        "        df = pd.read_csv(input_file, skiprows=1)\n",
        "\n",
        "        # Remove any rows that contain 'Downloaded from' or empty rows\n",
        "        df = df[~df['Commodity'].astype(str).str.contains('Downloaded|^$', na=False)]\n",
        "\n",
        "        # Remove any completely empty rows\n",
        "        df = df.dropna(how='all')\n",
        "\n",
        "        print(f\"Original data shape: {df.shape}\")\n",
        "        print(f\"Original columns: {df.columns.tolist()}\")\n",
        "        print(\"\\nFirst few rows of original data:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Process the data\n",
        "        print(\"\\nProcessing data...\")\n",
        "        df_processed = preprocess_rice_data(df)\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\n✓ Processing completed!\")\n",
        "        print(f\"Processed data shape: {df_processed.shape}\")\n",
        "        print(f\"\\nAll columns ({len(df_processed.columns)}):\")\n",
        "        for i, col in enumerate(df_processed.columns, 1):\n",
        "            print(f\"  {i}. {col}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SAMPLE OF PROCESSED DATA (First 5 rows)\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_processed.head().to_string())\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATA STATISTICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(df_processed[['Price_1KG', 'Price_1Q', 'Price_Max', 'Price_Min', 'Price_Range']].describe())\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASON DISTRIBUTION\")\n",
        "        print(\"=\"*80)\n",
        "        season_counts = df_processed['Season'].value_counts()\n",
        "        print(season_counts)\n",
        "        print(f\"\\nKharif: {season_counts.get('Kharif', 0)} records ({season_counts.get('Kharif', 0)/len(df_processed)*100:.1f}%)\")\n",
        "        print(f\"Rabi: {season_counts.get('Rabi', 0)} records ({season_counts.get('Rabi', 0)/len(df_processed)*100:.1f}%)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"DATE RANGE\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Earliest date: {df_processed['Date'].min().strftime('%d/%m/%Y')}\")\n",
        "        print(f\"Latest date: {df_processed['Date'].max().strftime('%d/%m/%Y')}\")\n",
        "        print(f\"Total days covered: {(df_processed['Date'].max() - df_processed['Date'].min()).days} days\")\n",
        "\n",
        "        # Save to CSV\n",
        "        df_processed.to_csv(output_file, index=False)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"✓ SUCCESS! Processed data saved to '{output_file}'\")\n",
        "        print(f\"Total records processed: {len(df_processed)}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n✗ Error: File '{input_file}' not found.\")\n",
        "        print(\"Please ensure the CSV file is in the same directory as this script.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error processing data: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4nDcJO9vBPg",
        "outputId": "413d72ed-d905-4f57-f95b-e56ed130ecf3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data from arhar_tur_whole.csv...\n",
            "Original data shape: (53, 6)\n",
            "Original columns: ['Commodity', 'Market', '1KG Price', '1Q Price', '1Q Max - Min', 'Date']\n",
            "\n",
            "First few rows of original data:\n",
            "                                      Commodity       Market 1KG Price  \\\n",
            "0       Arhar (Tur/Red Gram)(Whole) - Angur Imp  Bhadravathi   ₹ 73.50   \n",
            "1   Arhar (Tur/Red Gram)(Whole) - Arhar (Whole)  Chitradurga   ₹ 51.69   \n",
            "2   Arhar (Tur/Red Gram)(Whole) - Arhar (Whole)       Haveri   ₹ 55.00   \n",
            "3  Arhar (Tur/Red Gram)(Whole) - Arhar Dal(Tur)      Raichur   ₹ 60.89   \n",
            "4             Arhar (Tur/Red Gram)(Whole) - Red      Raichur   ₹ 69.98   \n",
            "\n",
            "     1Q Price         1Q Max - Min        Date  \n",
            "0  ₹ 7,350.00  ₹ 7350 - ₹ 7,350.00  08/10/2025  \n",
            "1  ₹ 5,169.00  ₹ 5169 - ₹ 5,169.00  06/10/2025  \n",
            "2  ₹ 5,500.00         ₹ 0 - ₹ 0.00  19/05/2025  \n",
            "3  ₹ 6,089.00         ₹ 0 - ₹ 0.00  08/05/2025  \n",
            "4  ₹ 6,998.00         ₹ 0 - ₹ 0.00  08/05/2025  \n",
            "\n",
            "Processing data...\n",
            "\n",
            "✓ Processing completed!\n",
            "Processed data shape: (53, 29)\n",
            "\n",
            "All columns (29):\n",
            "  1. Date\n",
            "  2. Commodity\n",
            "  3. Season\n",
            "  4. Price_1KG\n",
            "  5. Price_1Q\n",
            "  6. Price_Max\n",
            "  7. Price_Min\n",
            "  8. Price_Range\n",
            "  9. Price_1KG_Lag_1\n",
            "  10. Price_1KG_Lag_7\n",
            "  11. Price_1KG_Lag_14\n",
            "  12. Price_1KG_Lag_30\n",
            "  13. Price_1KG_RollingAvg_7\n",
            "  14. Price_1KG_RollingAvg_14\n",
            "  15. Price_1KG_RollingAvg_30\n",
            "  16. Price_1KG_RollingStd_7\n",
            "  17. Price_1KG_RollingStd_14\n",
            "  18. Price_1KG_RollingStd_30\n",
            "  19. Price_1KG_Change\n",
            "  20. Price_1KG_PctChange\n",
            "  21. Day\n",
            "  22. Month\n",
            "  23. Year\n",
            "  24. DayOfWeek\n",
            "  25. Quarter\n",
            "  26. WeekOfYear\n",
            "  27. Price_Range_RollingAvg_7\n",
            "  28. Price_1KG_EMA_7\n",
            "  29. Price_1KG_EMA_30\n",
            "\n",
            "================================================================================\n",
            "SAMPLE OF PROCESSED DATA (First 5 rows)\n",
            "================================================================================\n",
            "        Date Commodity  Season  Price_1KG  Price_1Q  Price_Max  Price_Min  Price_Range  Price_1KG_Lag_1  Price_1KG_Lag_7  Price_1KG_Lag_14  Price_1KG_Lag_30  Price_1KG_RollingAvg_7  Price_1KG_RollingAvg_14  Price_1KG_RollingAvg_30  Price_1KG_RollingStd_7  Price_1KG_RollingStd_14  Price_1KG_RollingStd_30  Price_1KG_Change  Price_1KG_PctChange  Day  Month  Year  DayOfWeek  Quarter  WeekOfYear  Price_Range_RollingAvg_7  Price_1KG_EMA_7  Price_1KG_EMA_30\n",
            "0 2023-01-18       Tur    Rabi      42.82    4282.0     4282.0     4282.0          0.0              NaN              NaN               NaN               NaN               42.820000                42.820000                42.820000                     NaN                      NaN                      NaN               NaN                  NaN   18      1  2023          2        1           3                  0.000000        42.820000         42.820000\n",
            "1 2023-01-20       Tur    Rabi      66.00    6600.0     6600.0     6600.0          0.0            42.82              NaN               NaN               NaN               54.410000                54.410000                54.410000               16.390735                16.390735                16.390735             23.18             0.541336   20      1  2023          4        1           3                  0.000000        48.615000         44.315484\n",
            "2 2023-02-03       Tur    Rabi      91.93    9193.0    11589.0     9100.0       2489.0            66.00              NaN               NaN               NaN               66.916667                66.916667                66.916667               24.567829                24.567829                24.567829             25.93             0.392879    3      2  2023          4        1           5                829.666667        59.443750         47.387388\n",
            "3 2023-02-14       Tur    Rabi      54.81    5481.0     5600.0     4050.0       1550.0            91.93              NaN               NaN               NaN               63.890000                63.890000                63.890000               20.953003                20.953003                20.953003            -37.12            -0.403785   14      2  2023          1        1           7               1009.750000        58.285313         47.866266\n",
            "4 2023-06-28       Tur  Kharif      90.00    9000.0     9000.0     9000.0          0.0            54.81              NaN               NaN               NaN               69.112000                69.112000                69.112000               21.578176                21.578176                21.578176             35.19             0.642036   28      6  2023          2        2          26                807.800000        66.213984         50.584572\n",
            "\n",
            "================================================================================\n",
            "DATA STATISTICS\n",
            "================================================================================\n",
            "        Price_1KG      Price_1Q     Price_Max     Price_Min  Price_Range\n",
            "count   53.000000     53.000000     53.000000     53.000000    53.000000\n",
            "mean    67.901132   6790.113208   6515.396226   5719.132075   796.264151\n",
            "std     15.882967   1588.296725   2764.147715   2544.362343  1043.926153\n",
            "min     42.820000   4282.000000      0.000000      0.000000     0.000000\n",
            "25%     55.000000   5500.000000   5600.000000   4619.000000     0.000000\n",
            "50%     69.980000   6998.000000   6919.000000   6150.000000   414.000000\n",
            "75%     74.000000   7400.000000   7800.000000   7050.000000  1430.000000\n",
            "max    105.000000  10500.000000  12000.000000  10500.000000  5550.000000\n",
            "\n",
            "================================================================================\n",
            "SEASON DISTRIBUTION\n",
            "================================================================================\n",
            "Season\n",
            "Rabi      40\n",
            "Kharif    13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Kharif: 13 records (24.5%)\n",
            "Rabi: 40 records (75.5%)\n",
            "\n",
            "================================================================================\n",
            "DATE RANGE\n",
            "================================================================================\n",
            "Earliest date: 18/01/2023\n",
            "Latest date: 08/10/2025\n",
            "Total days covered: 994 days\n",
            "\n",
            "================================================================================\n",
            "✓ SUCCESS! Processed data saved to 'tur_prices_processed.csv'\n",
            "Total records processed: 53\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "B6sww6GAxabG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CropPriceForecaster:\n",
        "    \"\"\"\n",
        "    Multi-crop price forecasting system for seasonal predictions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.crop_encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"\n",
        "        Prepare data for modeling\n",
        "        \"\"\"\n",
        "        print(\"Preparing data for modeling...\")\n",
        "\n",
        "        # Create a copy\n",
        "        data = df.copy()\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le_commodity = LabelEncoder()\n",
        "        data['Commodity_Encoded'] = le_commodity.fit_transform(data['Commodity'])\n",
        "\n",
        "        le_season = LabelEncoder()\n",
        "        data['Season_Encoded'] = le_season.fit_transform(data['Season'])\n",
        "\n",
        "        # Store encoders\n",
        "        self.crop_encoders['commodity'] = le_commodity\n",
        "        self.crop_encoders['season'] = le_season\n",
        "\n",
        "        # Create additional features\n",
        "        data['Days_Since_Start'] = (data['Date'] - data['Date'].min()).dt.days\n",
        "\n",
        "        # Seasonal indicators\n",
        "        data['Is_Kharif'] = (data['Season'] == 'Kharif').astype(int)\n",
        "        data['Is_Rabi'] = (data['Season'] == 'Rabi').astype(int)\n",
        "\n",
        "        # Cyclical time features (sine/cosine for month)\n",
        "        data['Month_Sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
        "        data['Month_Cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def select_features(self, data):\n",
        "        \"\"\"\n",
        "        Select relevant features for modeling\n",
        "        \"\"\"\n",
        "        # Define feature columns (excluding target and identifiers)\n",
        "        exclude_cols = ['Date', 'Commodity', 'Season', 'Price_1KG', 'Price_1Q']\n",
        "\n",
        "        feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
        "\n",
        "        # Remove columns with too many NaN values\n",
        "        feature_cols = [col for col in feature_cols if data[col].isna().sum() / len(data) < 0.5]\n",
        "\n",
        "        self.feature_columns = feature_cols\n",
        "        print(f\"Selected {len(feature_cols)} features for modeling\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def train_models(self, df, target_col='Price_1KG'):\n",
        "        \"\"\"\n",
        "        Train separate models for each crop\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TRAINING MODELS FOR EACH CROP\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        feature_cols = self.select_features(data)\n",
        "\n",
        "        # Get unique crops\n",
        "        crops = data['Commodity'].unique()\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nTraining model for: {crop}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Filter data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "\n",
        "            # Remove rows with NaN in target\n",
        "            crop_data = crop_data.dropna(subset=[target_col])\n",
        "\n",
        "            if len(crop_data) < 10:\n",
        "                print(f\"  ⚠ Insufficient data for {crop} (only {len(crop_data)} records). Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Prepare features and target\n",
        "            X = crop_data[feature_cols].fillna(crop_data[feature_cols].median())\n",
        "            y = crop_data[target_col]\n",
        "\n",
        "            # Split data (time-series aware)\n",
        "            split_idx = int(len(X) * 0.8)\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            # Train model - using Gradient Boosting for better performance\n",
        "            model = GradientBoostingRegressor(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=5,\n",
        "                min_samples_split=5,\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred = model.predict(X_train_scaled)\n",
        "            test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            train_mae = mean_absolute_error(y_train, train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, test_pred)\n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "            print(f\"  Train MAE: ₹{train_mae:.2f} | R²: {train_r2:.3f}\")\n",
        "            print(f\"  Test MAE:  ₹{test_mae:.2f} | R²: {test_r2:.3f}\")\n",
        "\n",
        "            # Store model and scaler\n",
        "            self.models[crop] = model\n",
        "            self.scalers[crop] = scaler\n",
        "\n",
        "            results.append({\n",
        "                'Crop': crop,\n",
        "                'Train_MAE': train_mae,\n",
        "                'Test_MAE': test_mae,\n",
        "                'Train_R2': train_r2,\n",
        "                'Test_R2': test_r2,\n",
        "                'Training_Samples': len(X_train),\n",
        "                'Test_Samples': len(X_test)\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL TRAINING SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(results_df.to_string(index=False))\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def predict_seasonal_prices(self, df, forecast_year=2026):\n",
        "        \"\"\"\n",
        "        Predict prices for next Kharif and Rabi seasons\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"PREDICTING PRICES FOR YEAR {forecast_year}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        crops = list(self.models.keys())\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nGenerating predictions for: {crop}\")\n",
        "\n",
        "            # Get latest data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "            latest_record = crop_data.iloc[-1]\n",
        "\n",
        "            # Get historical averages for this crop\n",
        "            kharif_avg = crop_data[crop_data['Season'] == 'Kharif']['Price_1KG'].mean()\n",
        "            rabi_avg = crop_data[crop_data['Season'] == 'Rabi']['Price_1KG'].mean()\n",
        "\n",
        "            # Define prediction dates for Kharif and Rabi\n",
        "            seasons = [\n",
        "                {\n",
        "                    'season': 'Kharif',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-07-15'),  # Mid-Kharif\n",
        "                    'month': 7,\n",
        "                    'is_kharif': 1,\n",
        "                    'is_rabi': 0\n",
        "                },\n",
        "                {\n",
        "                    'season': 'Rabi',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-01-15'),  # Mid-Rabi\n",
        "                    'month': 1,\n",
        "                    'is_kharif': 0,\n",
        "                    'is_rabi': 1\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            for season_info in seasons:\n",
        "                # Create feature vector for prediction\n",
        "                pred_features = latest_record[self.feature_columns].copy()\n",
        "\n",
        "                # Update time-based features\n",
        "                pred_features['Month'] = season_info['month']\n",
        "                pred_features['Year'] = forecast_year\n",
        "                pred_features['Is_Kharif'] = season_info['is_kharif']\n",
        "                pred_features['Is_Rabi'] = season_info['is_rabi']\n",
        "                pred_features['Season_Encoded'] = 0 if season_info['season'] == 'Kharif' else 1\n",
        "                pred_features['Month_Sin'] = np.sin(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Month_Cos'] = np.cos(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Quarter'] = (season_info['month'] - 1) // 3 + 1\n",
        "\n",
        "                # Calculate days since start\n",
        "                days_since_start = (season_info['date'] - data['Date'].min()).days\n",
        "                pred_features['Days_Since_Start'] = days_since_start\n",
        "\n",
        "                # Fill any remaining NaN values\n",
        "                pred_features = pred_features.fillna(crop_data[self.feature_columns].median())\n",
        "\n",
        "                # Prepare for prediction\n",
        "                X_pred = pred_features.values.reshape(1, -1)\n",
        "                X_pred_scaled = self.scalers[crop].transform(X_pred)\n",
        "\n",
        "                # Make prediction\n",
        "                predicted_price = self.models[crop].predict(X_pred_scaled)[0]\n",
        "\n",
        "                # Calculate confidence based on historical volatility\n",
        "                historical_std = crop_data['Price_1KG'].std()\n",
        "                confidence_interval = 1.96 * historical_std  # 95% CI\n",
        "\n",
        "                predictions.append({\n",
        "                    'Crop': crop,\n",
        "                    'Season': season_info['season'],\n",
        "                    'Year': forecast_year,\n",
        "                    'Predicted_Price_1KG': round(predicted_price, 2),\n",
        "                    'Lower_Bound': round(predicted_price - confidence_interval, 2),\n",
        "                    'Upper_Bound': round(predicted_price + confidence_interval, 2),\n",
        "                    'Historical_Avg': round(kharif_avg if season_info['season'] == 'Kharif' else rabi_avg, 2),\n",
        "                    'Change_from_Avg': round(predicted_price - (kharif_avg if season_info['season'] == 'Kharif' else rabi_avg), 2)\n",
        "                })\n",
        "\n",
        "        predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASONAL PRICE PREDICTIONS\")\n",
        "        print(\"=\"*80)\n",
        "        print(predictions_df.to_string(index=False))\n",
        "\n",
        "        return predictions_df\n",
        "\n",
        "    def save_models(self, filepath='crop_price_models.pkl'):\n",
        "        \"\"\"\n",
        "        Save trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = {\n",
        "            'models': self.models,\n",
        "            'scalers': self.scalers,\n",
        "            'crop_encoders': self.crop_encoders,\n",
        "            'feature_columns': self.feature_columns\n",
        "        }\n",
        "        joblib.dump(model_data, filepath)\n",
        "        print(f\"\\n✓ Models saved to {filepath}\")\n",
        "\n",
        "    def load_models(self, filepath='crop_price_models.pkl'):\n",
        "        \"\"\"\n",
        "        Load trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = joblib.load(filepath)\n",
        "        self.models = model_data['models']\n",
        "        self.scalers = model_data['scalers']\n",
        "        self.crop_encoders = model_data['crop_encoders']\n",
        "        self.feature_columns = model_data['feature_columns']\n",
        "        print(f\"✓ Models loaded from {filepath}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Bvft8vzJxcB6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load processed data\n",
        "    input_files = [\n",
        "        'rice_prices_processed.csv',\n",
        "        'wheat_prices_processed.csv',\n",
        "        'groundnut_prices_processed.csv','jowar_prices_processed.csv','onion_prices_processed.csv','potato_prices_processed.csv',\n",
        "        'ragi_prices_processed.csv','soyabean_prices_processed.csv','tur_prices_processed.csv'\n",
        "        # Add more crop files here\n",
        "    ]\n",
        "\n",
        "    # For demonstration, we'll use rice data\n",
        "    # Replace this with actual loading of all 8 crops\n",
        "    print(\"\\nLoading data...\")\n",
        "\n",
        "    try:\n",
        "        # Load all crop data and combine\n",
        "        all_data = []\n",
        "        for file in input_files:\n",
        "            try:\n",
        "                df = pd.read_csv(file)\n",
        "                all_data.append(df)\n",
        "                print(f\"  ✓ Loaded {file}: {len(df)} records\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"  ⚠ File not found: {file}\")\n",
        "                continue\n",
        "\n",
        "        if not all_data:\n",
        "            print(\"\\n⚠ No data files found. Using sample data...\")\n",
        "            # Load single file for demonstration\n",
        "            df = pd.read_csv('rice_prices_processed.csv')\n",
        "            all_data = [df]\n",
        "\n",
        "        # Combine all crop data\n",
        "        combined_data = pd.concat(all_data, ignore_index=True)\n",
        "        print(f\"\\nTotal combined data: {len(combined_data)} records\")\n",
        "        print(f\"Crops in dataset: {combined_data['Commodity'].unique()}\")\n",
        "\n",
        "        # Initialize forecaster\n",
        "        forecaster = CropPriceForecaster()\n",
        "\n",
        "        # Train models\n",
        "        training_results = forecaster.train_models(combined_data)\n",
        "\n",
        "        # Make predictions for next seasons\n",
        "        predictions = forecaster.predict_seasonal_prices(combined_data, forecast_year=2026)\n",
        "\n",
        "        # Save predictions to CSV\n",
        "        predictions.to_csv('seasonal_price_predictions_2026.csv', index=False)\n",
        "        print(\"\\n✓ Predictions saved to 'seasonal_price_predictions_2026.csv'\")\n",
        "\n",
        "        # Save models for future use\n",
        "        forecaster.save_models('crop_price_models.pkl')\n",
        "\n",
        "        # Generate summary report\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREDICTION SUMMARY BY SEASON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for season in ['Kharif', 'Rabi']:\n",
        "            season_data = predictions[predictions['Season'] == season]\n",
        "            print(f\"\\n{season} Season 2026:\")\n",
        "            print(f\"  Average predicted price: ₹{season_data['Predicted_Price_1KG'].mean():.2f}\")\n",
        "            print(f\"  Highest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmax(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].max():.2f}\")\n",
        "            print(f\"  Lowest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmin(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].min():.2f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✓ FORECASTING COMPLETE!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ4LBjFTxjRB",
        "outputId": "55e7c120-cbef-4f39-a22e-27b194af820a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\n",
            "================================================================================\n",
            "\n",
            "Loading data...\n",
            "  ✓ Loaded rice_prices_processed.csv: 106 records\n",
            "  ✓ Loaded wheat_prices_processed.csv: 52 records\n",
            "  ✓ Loaded groundnut_prices_processed.csv: 51 records\n",
            "  ✓ Loaded jowar_prices_processed.csv: 67 records\n",
            "  ✓ Loaded onion_prices_processed.csv: 58 records\n",
            "  ✓ Loaded potato_prices_processed.csv: 42 records\n",
            "  ✓ Loaded ragi_prices_processed.csv: 55 records\n",
            "  ✓ Loaded soyabean_prices_processed.csv: 25 records\n",
            "  ✓ Loaded tur_prices_processed.csv: 53 records\n",
            "\n",
            "Total combined data: 509 records\n",
            "Crops in dataset: ['Rice' 'Wheat' 'Groundnut' 'Jowar' 'Onion' 'Potato' 'Ragi' 'Soyabean'\n",
            " 'Tur']\n",
            "\n",
            "================================================================================\n",
            "TRAINING MODELS FOR EACH CROP\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "\n",
            "✗ Error: unsupported operand type(s) for -: 'str' and 'str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/ops/array_ops.py\", line 218, in _na_arithmetic_op\n",
            "    result = func(left, right)\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "TypeError: unsupported operand type(s) for -: 'str' and 'str'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3078157669.py\", line 49, in main\n",
            "    training_results = forecaster.train_models(combined_data)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3261995292.py\", line 70, in train_models\n",
            "    data = self.prepare_data(df)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3261995292.py\", line 33, in prepare_data\n",
            "    data['Days_Since_Start'] = (data['Date'] - data['Date'].min()).dt.days\n",
            "                                ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
            "    return method(self, other)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py\", line 194, in __sub__\n",
            "    return self._arith_method(other, operator.sub)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\", line 6135, in _arith_method\n",
            "    return base.IndexOpsMixin._arith_method(self, other, op)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\", line 1382, in _arith_method\n",
            "    result = ops.arithmetic_op(lvalues, rvalues, op)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/ops/array_ops.py\", line 283, in arithmetic_op\n",
            "    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/ops/array_ops.py\", line 227, in _na_arithmetic_op\n",
            "    result = _masked_arith_op(left, right, op)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/ops/array_ops.py\", line 182, in _masked_arith_op\n",
            "    result[mask] = op(xrav[mask], y)\n",
            "                   ^^^^^^^^^^^^^^^^^\n",
            "TypeError: unsupported operand type(s) for -: 'str' and 'str'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CropPriceForecaster:\n",
        "    \"\"\"\n",
        "    Multi-crop price forecasting system for seasonal predictions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.crop_encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"\n",
        "        Prepare data for modeling\n",
        "        \"\"\"\n",
        "        print(\"Preparing data for modeling...\")\n",
        "\n",
        "        # Create a copy\n",
        "        data = df.copy()\n",
        "\n",
        "        # Convert Date to datetime if it's not already\n",
        "        if not pd.api.types.is_datetime64_any_dtype(data['Date']):\n",
        "            print(\"  Converting Date column to datetime...\")\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le_commodity = LabelEncoder()\n",
        "        data['Commodity_Encoded'] = le_commodity.fit_transform(data['Commodity'])\n",
        "\n",
        "        le_season = LabelEncoder()\n",
        "        data['Season_Encoded'] = le_season.fit_transform(data['Season'])\n",
        "\n",
        "        # Store encoders\n",
        "        self.crop_encoders['commodity'] = le_commodity\n",
        "        self.crop_encoders['season'] = le_season\n",
        "\n",
        "        # Create additional features\n",
        "        data['Days_Since_Start'] = (data['Date'] - data['Date'].min()).dt.days\n",
        "\n",
        "        # Seasonal indicators\n",
        "        data['Is_Kharif'] = (data['Season'] == 'Kharif').astype(int)\n",
        "        data['Is_Rabi'] = (data['Season'] == 'Rabi').astype(int)\n",
        "\n",
        "        # Cyclical time features (sine/cosine for month)\n",
        "        data['Month_Sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
        "        data['Month_Cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def select_features(self, data):\n",
        "        \"\"\"\n",
        "        Select relevant features for modeling\n",
        "        \"\"\"\n",
        "        # Define feature columns (excluding target and identifiers)\n",
        "        exclude_cols = ['Date', 'Commodity', 'Season', 'Price_1KG', 'Price_1Q']\n",
        "\n",
        "        feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
        "\n",
        "        # Remove columns with too many NaN values\n",
        "        feature_cols = [col for col in feature_cols if data[col].isna().sum() / len(data) < 0.5]\n",
        "\n",
        "        self.feature_columns = feature_cols\n",
        "        print(f\"Selected {len(feature_cols)} features for modeling\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def train_models(self, df, target_col='Price_1KG'):\n",
        "        \"\"\"\n",
        "        Train separate models for each crop\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TRAINING MODELS FOR EACH CROP\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        feature_cols = self.select_features(data)\n",
        "\n",
        "        # Get unique crops\n",
        "        crops = data['Commodity'].unique()\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nTraining model for: {crop}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Filter data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "\n",
        "            # Remove rows with NaN in target\n",
        "            crop_data = crop_data.dropna(subset=[target_col])\n",
        "\n",
        "            if len(crop_data) < 10:\n",
        "                print(f\"  ⚠ Insufficient data for {crop} (only {len(crop_data)} records). Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Prepare features and target\n",
        "            X = crop_data[feature_cols].fillna(crop_data[feature_cols].median())\n",
        "            y = crop_data[target_col]\n",
        "\n",
        "            # Split data (time-series aware)\n",
        "            split_idx = int(len(X) * 0.8)\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            # Train model - using Gradient Boosting for better performance\n",
        "            model = GradientBoostingRegressor(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=5,\n",
        "                min_samples_split=5,\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred = model.predict(X_train_scaled)\n",
        "            test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            train_mae = mean_absolute_error(y_train, train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, test_pred)\n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "            print(f\"  Train MAE: ₹{train_mae:.2f} | R²: {train_r2:.3f}\")\n",
        "            print(f\"  Test MAE:  ₹{test_mae:.2f} | R²: {test_r2:.3f}\")\n",
        "\n",
        "            # Store model and scaler\n",
        "            self.models[crop] = model\n",
        "            self.scalers[crop] = scaler\n",
        "\n",
        "            results.append({\n",
        "                'Crop': crop,\n",
        "                'Train_MAE': train_mae,\n",
        "                'Test_MAE': test_mae,\n",
        "                'Train_R2': train_r2,\n",
        "                'Test_R2': test_r2,\n",
        "                'Training_Samples': len(X_train),\n",
        "                'Test_Samples': len(X_test)\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL TRAINING SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(results_df.to_string(index=False))\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def predict_seasonal_prices(self, df, forecast_year=2026):\n",
        "        \"\"\"\n",
        "        Predict prices for next Kharif and Rabi seasons\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"PREDICTING PRICES FOR YEAR {forecast_year}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        crops = list(self.models.keys())\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nGenerating predictions for: {crop}\")\n",
        "\n",
        "            # Get latest data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "            latest_record = crop_data.iloc[-1]\n",
        "\n",
        "            # Get historical averages for this crop\n",
        "            kharif_avg = crop_data[crop_data['Season'] == 'Kharif']['Price_1KG'].mean()\n",
        "            rabi_avg = crop_data[crop_data['Season'] == 'Rabi']['Price_1KG'].mean()\n",
        "\n",
        "            # Define prediction dates for Kharif and Rabi\n",
        "            seasons = [\n",
        "                {\n",
        "                    'season': 'Kharif',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-07-15'),  # Mid-Kharif\n",
        "                    'month': 7,\n",
        "                    'is_kharif': 1,\n",
        "                    'is_rabi': 0\n",
        "                },\n",
        "                {\n",
        "                    'season': 'Rabi',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-01-15'),  # Mid-Rabi\n",
        "                    'month': 1,\n",
        "                    'is_kharif': 0,\n",
        "                    'is_rabi': 1\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            for season_info in seasons:\n",
        "                # Create feature vector for prediction\n",
        "                pred_features = latest_record[self.feature_columns].copy()\n",
        "\n",
        "                # Update time-based features\n",
        "                pred_features['Month'] = season_info['month']\n",
        "                pred_features['Year'] = forecast_year\n",
        "                pred_features['Is_Kharif'] = season_info['is_kharif']\n",
        "                pred_features['Is_Rabi'] = season_info['is_rabi']\n",
        "                pred_features['Season_Encoded'] = 0 if season_info['season'] == 'Kharif' else 1\n",
        "                pred_features['Month_Sin'] = np.sin(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Month_Cos'] = np.cos(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Quarter'] = (season_info['month'] - 1) // 3 + 1\n",
        "\n",
        "                # Calculate days since start\n",
        "                days_since_start = (season_info['date'] - data['Date'].min()).days\n",
        "                pred_features['Days_Since_Start'] = days_since_start\n",
        "\n",
        "                # Fill any remaining NaN values\n",
        "                pred_features = pred_features.fillna(crop_data[self.feature_columns].median())\n",
        "\n",
        "                # Prepare for prediction\n",
        "                X_pred = pred_features.values.reshape(1, -1)\n",
        "                X_pred_scaled = self.scalers[crop].transform(X_pred)\n",
        "\n",
        "                # Make prediction\n",
        "                predicted_price = self.models[crop].predict(X_pred_scaled)[0]\n",
        "\n",
        "                # Calculate confidence based on historical volatility\n",
        "                historical_std = crop_data['Price_1KG'].std()\n",
        "                confidence_interval = 1.96 * historical_std  # 95% CI\n",
        "\n",
        "                predictions.append({\n",
        "                    'Crop': crop,\n",
        "                    'Season': season_info['season'],\n",
        "                    'Year': forecast_year,\n",
        "                    'Predicted_Price_1KG': round(predicted_price, 2),\n",
        "                    'Lower_Bound': round(predicted_price - confidence_interval, 2),\n",
        "                    'Upper_Bound': round(predicted_price + confidence_interval, 2),\n",
        "                    'Historical_Avg': round(kharif_avg if season_info['season'] == 'Kharif' else rabi_avg, 2),\n",
        "                    'Change_from_Avg': round(predicted_price - (kharif_avg if season_info['season'] == 'Kharif' else rabi_avg), 2)\n",
        "                })\n",
        "\n",
        "        predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASONAL PRICE PREDICTIONS\")\n",
        "        print(\"=\"*80)\n",
        "        print(predictions_df.to_string(index=False))\n",
        "\n",
        "        return predictions_df\n",
        "\n",
        "    def save_models(self, filepath='crop_price_models.pkl'):\n",
        "        \"\"\"\n",
        "        Save trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = {\n",
        "            'models': self.models,\n",
        "            'scalers': self.scalers,\n",
        "            'crop_encoders': self.crop_encoders,\n",
        "            'feature_columns': self.feature_columns\n",
        "        }\n",
        "        joblib.dump(model_data, filepath)\n",
        "        print(f\"\\n✓ Models saved to {filepath}\")\n",
        "\n",
        "    def load_models(self, filepath='crop_price_models.pkl'):\n",
        "        \"\"\"\n",
        "        Load trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = joblib.load(filepath)\n",
        "        self.models = model_data['models']\n",
        "        self.scalers = model_data['scalers']\n",
        "        self.crop_encoders = model_data['crop_encoders']\n",
        "        self.feature_columns = model_data['feature_columns']\n",
        "        print(f\"✓ Models loaded from {filepath}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load processed data\n",
        "    input_files = [\n",
        "        'rice_prices_processed.csv',\n",
        "        'wheat_prices_processed.csv',\n",
        "        'groundnut_prices_processed.csv','jowar_prices_processed.csv','onion_prices_processed.csv','potato_prices_processed.csv',\n",
        "        'ragi_prices_processed.csv','soyabean_prices_processed.csv','tur_prices_processed.csv'\n",
        "        # Add more crop files here\n",
        "    ]\n",
        "\n",
        "    # For demonstration, we'll use rice data\n",
        "    # Replace this with actual loading of all 8 crops\n",
        "    print(\"\\nLoading data...\")\n",
        "\n",
        "    try:\n",
        "        # Load all crop data and combine\n",
        "        all_data = []\n",
        "        for file in input_files:\n",
        "            try:\n",
        "                df = pd.read_csv(file)\n",
        "                all_data.append(df)\n",
        "                print(f\"  ✓ Loaded {file}: {len(df)} records\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"  ⚠ File not found: {file}\")\n",
        "                continue\n",
        "\n",
        "        if not all_data:\n",
        "            print(\"\\n⚠ No data files found. Using sample data...\")\n",
        "            # Load single file for demonstration\n",
        "            df = pd.read_csv('rice_prices_processed.csv')\n",
        "            all_data = [df]\n",
        "\n",
        "        # Combine all crop data\n",
        "        combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "        # Ensure Date column is datetime\n",
        "        if not pd.api.types.is_datetime64_any_dtype(combined_data['Date']):\n",
        "            print(\"\\nConverting Date column to datetime format...\")\n",
        "            try:\n",
        "                combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        print(f\"\\nTotal combined data: {len(combined_data)} records\")\n",
        "        print(f\"Crops in dataset: {combined_data['Commodity'].unique()}\")\n",
        "        print(f\"Date range: {combined_data['Date'].min()} to {combined_data['Date'].max()}\")\n",
        "\n",
        "        # Initialize forecaster\n",
        "        forecaster = CropPriceForecaster()\n",
        "\n",
        "        # Train models\n",
        "        training_results = forecaster.train_models(combined_data)\n",
        "\n",
        "        # Make predictions for next seasons\n",
        "        predictions = forecaster.predict_seasonal_prices(combined_data, forecast_year=2026)\n",
        "\n",
        "        # Save predictions to CSV\n",
        "        predictions.to_csv('seasonal_price_predictions_2026.csv', index=False)\n",
        "        print(\"\\n✓ Predictions saved to 'seasonal_price_predictions_2026.csv'\")\n",
        "\n",
        "        # Save models for future use\n",
        "        forecaster.save_models('crop_price_models.pkl')\n",
        "\n",
        "        # Generate summary report\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREDICTION SUMMARY BY SEASON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for season in ['Kharif', 'Rabi']:\n",
        "            season_data = predictions[predictions['Season'] == season]\n",
        "            print(f\"\\n{season} Season 2026:\")\n",
        "            print(f\"  Average predicted price: ₹{season_data['Predicted_Price_1KG'].mean():.2f}\")\n",
        "            print(f\"  Highest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmax(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].max():.2f}\")\n",
        "            print(f\"  Lowest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmin(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].min():.2f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✓ FORECASTING COMPLETE!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2hWcXLAyP0I",
        "outputId": "51cf86f8-93c1-4f04-8119-664987b179a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\n",
            "================================================================================\n",
            "\n",
            "Loading data...\n",
            "  ✓ Loaded rice_prices_processed.csv: 106 records\n",
            "  ✓ Loaded wheat_prices_processed.csv: 52 records\n",
            "  ✓ Loaded groundnut_prices_processed.csv: 51 records\n",
            "  ✓ Loaded jowar_prices_processed.csv: 67 records\n",
            "  ✓ Loaded onion_prices_processed.csv: 58 records\n",
            "  ✓ Loaded potato_prices_processed.csv: 42 records\n",
            "  ✓ Loaded ragi_prices_processed.csv: 55 records\n",
            "  ✓ Loaded soyabean_prices_processed.csv: 25 records\n",
            "  ✓ Loaded tur_prices_processed.csv: 53 records\n",
            "\n",
            "Converting Date column to datetime format...\n",
            "\n",
            "Total combined data: 509 records\n",
            "Crops in dataset: ['Rice' 'Wheat' 'Groundnut' 'Jowar' 'Onion' 'Potato' 'Ragi' 'Soyabean'\n",
            " 'Tur']\n",
            "Date range: 2022-08-04 00:00:00 to 2025-10-23 00:00:00\n",
            "\n",
            "================================================================================\n",
            "TRAINING MODELS FOR EACH CROP\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "Selected 30 features for modeling\n",
            "\n",
            "Training model for: Rice\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹1.53 | R²: 0.912\n",
            "\n",
            "Training model for: Wheat\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹0.79 | R²: 0.921\n",
            "\n",
            "Training model for: Groundnut\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹14.66 | R²: -0.530\n",
            "\n",
            "Training model for: Jowar\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹7.36 | R²: -1.599\n",
            "\n",
            "Training model for: Onion\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹1.61 | R²: 0.699\n",
            "\n",
            "Training model for: Potato\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹1.29 | R²: 0.753\n",
            "\n",
            "Training model for: Ragi\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹3.91 | R²: 0.356\n",
            "\n",
            "Training model for: Soyabean\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹2.86 | R²: -8.414\n",
            "\n",
            "Training model for: Tur\n",
            "--------------------------------------------------\n",
            "  Train MAE: ₹0.00 | R²: 1.000\n",
            "  Test MAE:  ₹12.21 | R²: -1.248\n",
            "\n",
            "================================================================================\n",
            "MODEL TRAINING SUMMARY\n",
            "================================================================================\n",
            "     Crop  Train_MAE  Test_MAE  Train_R2   Test_R2  Training_Samples  Test_Samples\n",
            "     Rice   0.002696  1.528337       1.0  0.911747                84            22\n",
            "    Wheat   0.000537  0.789296       1.0  0.921424                41            11\n",
            "Groundnut   0.000673 14.657699       1.0 -0.529886                40            11\n",
            "    Jowar   0.000893  7.362007       1.0 -1.598511                53            14\n",
            "    Onion   0.002947  1.614022       1.0  0.699420                46            12\n",
            "   Potato   0.000247  1.287265       1.0  0.752582                33             9\n",
            "     Ragi   0.000449  3.905728       1.0  0.355601                44            11\n",
            " Soyabean   0.000412  2.859105       1.0 -8.413695                20             5\n",
            "      Tur   0.000759 12.208515       1.0 -1.248224                42            11\n",
            "\n",
            "================================================================================\n",
            "PREDICTING PRICES FOR YEAR 2026\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "\n",
            "Generating predictions for: Rice\n",
            "\n",
            "Generating predictions for: Wheat\n",
            "\n",
            "Generating predictions for: Groundnut\n",
            "\n",
            "Generating predictions for: Jowar\n",
            "\n",
            "Generating predictions for: Onion\n",
            "\n",
            "Generating predictions for: Potato\n",
            "\n",
            "Generating predictions for: Ragi\n",
            "\n",
            "Generating predictions for: Soyabean\n",
            "\n",
            "Generating predictions for: Tur\n",
            "\n",
            "================================================================================\n",
            "SEASONAL PRICE PREDICTIONS\n",
            "================================================================================\n",
            "     Crop Season  Year  Predicted_Price_1KG  Lower_Bound  Upper_Bound  Historical_Avg  Change_from_Avg\n",
            "     Rice Kharif  2026                41.60        12.07        71.13           34.38             7.23\n",
            "     Rice   Rabi  2026                41.69        12.16        71.22           42.61            -0.92\n",
            "    Wheat Kharif  2026                37.30        22.99        51.60           31.15             6.15\n",
            "    Wheat   Rabi  2026                37.12        22.82        51.42           29.39             7.73\n",
            "Groundnut Kharif  2026                72.90        44.65       101.15           56.20            16.70\n",
            "Groundnut   Rabi  2026                72.90        44.65       101.15           52.44            20.46\n",
            "    Jowar Kharif  2026                17.43        -2.19        37.06           32.23           -14.79\n",
            "    Jowar   Rabi  2026                17.60        -2.03        37.22           26.95            -9.36\n",
            "    Onion Kharif  2026                16.11       -16.27        48.49           20.70            -4.59\n",
            "    Onion   Rabi  2026                16.13       -16.25        48.51           21.38            -5.26\n",
            "   Potato Kharif  2026                17.08         8.22        25.94           19.12            -2.04\n",
            "   Potato   Rabi  2026                16.96         8.10        25.82           19.17            -2.21\n",
            "     Ragi Kharif  2026                37.70        25.45        49.95           31.83             5.87\n",
            "     Ragi   Rabi  2026                37.67        25.42        49.92           31.01             6.66\n",
            " Soyabean Kharif  2026                36.79        27.08        46.51           42.22            -5.42\n",
            " Soyabean   Rabi  2026                36.84        27.13        46.56           41.90            -5.06\n",
            "      Tur Kharif  2026                72.58        41.45       103.71           65.68             6.90\n",
            "      Tur   Rabi  2026                72.58        41.45       103.72           68.62             3.96\n",
            "\n",
            "✓ Predictions saved to 'seasonal_price_predictions_2026.csv'\n",
            "\n",
            "✓ Models saved to crop_price_models.pkl\n",
            "\n",
            "================================================================================\n",
            "PREDICTION SUMMARY BY SEASON\n",
            "================================================================================\n",
            "\n",
            "Kharif Season 2026:\n",
            "  Average predicted price: ₹38.83\n",
            "  Highest: Groundnut - ₹72.90\n",
            "  Lowest: Onion - ₹16.11\n",
            "\n",
            "Rabi Season 2026:\n",
            "  Average predicted price: ₹38.83\n",
            "  Highest: Groundnut - ₹72.90\n",
            "  Lowest: Onion - ₹16.13\n",
            "\n",
            "================================================================================\n",
            "✓ FORECASTING COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CropPriceForecaster:\n",
        "    \"\"\"\n",
        "    Multi-crop price forecasting system for seasonal predictions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.crop_encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"\n",
        "        Prepare data for modeling\n",
        "        \"\"\"\n",
        "        print(\"Preparing data for modeling...\")\n",
        "\n",
        "        # Create a copy\n",
        "        data = df.copy()\n",
        "\n",
        "        # Convert Date to datetime if it's not already\n",
        "        if not pd.api.types.is_datetime64_any_dtype(data['Date']):\n",
        "            print(\"  Converting Date column to datetime...\")\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le_commodity = LabelEncoder()\n",
        "        data['Commodity_Encoded'] = le_commodity.fit_transform(data['Commodity'])\n",
        "\n",
        "        le_season = LabelEncoder()\n",
        "        data['Season_Encoded'] = le_season.fit_transform(data['Season'])\n",
        "\n",
        "        # Store encoders\n",
        "        self.crop_encoders['commodity'] = le_commodity\n",
        "        self.crop_encoders['season'] = le_season\n",
        "\n",
        "        # Create additional features\n",
        "        data['Days_Since_Start'] = (data['Date'] - data['Date'].min()).dt.days\n",
        "\n",
        "        # Seasonal indicators\n",
        "        data['Is_Kharif'] = (data['Season'] == 'Kharif').astype(int)\n",
        "        data['Is_Rabi'] = (data['Season'] == 'Rabi').astype(int)\n",
        "\n",
        "        # Cyclical time features (sine/cosine for month)\n",
        "        data['Month_Sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
        "        data['Month_Cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def select_features(self, data):\n",
        "        \"\"\"\n",
        "        Select relevant features for modeling - simplified to reduce overfitting\n",
        "        \"\"\"\n",
        "        # Use only the most important features to avoid overfitting\n",
        "        important_features = [\n",
        "            'Commodity_Encoded',\n",
        "            'Season_Encoded',\n",
        "            'Month',\n",
        "            'Year',\n",
        "            'Is_Kharif',\n",
        "            'Is_Rabi',\n",
        "            'Month_Sin',\n",
        "            'Month_Cos',\n",
        "            'Quarter',\n",
        "            'Days_Since_Start',\n",
        "            'Price_1KG_Lag_1',\n",
        "            'Price_1KG_Lag_7',\n",
        "            'Price_1KG_RollingAvg_7',\n",
        "            'Price_Max',\n",
        "            'Price_Min',\n",
        "            'Price_Range'\n",
        "        ]\n",
        "\n",
        "        # Only keep features that exist in the data\n",
        "        feature_cols = [col for col in important_features if col in data.columns]\n",
        "\n",
        "        # Remove columns with too many NaN values (>30%)\n",
        "        feature_cols = [col for col in feature_cols if data[col].isna().sum() / len(data) < 0.3]\n",
        "\n",
        "        self.feature_columns = feature_cols\n",
        "        print(f\"Selected {len(feature_cols)} features for modeling\")\n",
        "        print(f\"Features: {feature_cols}\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def train_models(self, df, target_col='Price_1KG'):\n",
        "        \"\"\"\n",
        "        Train separate models for each crop\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TRAINING MODELS FOR EACH CROP\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        feature_cols = self.select_features(data)\n",
        "\n",
        "        # Get unique crops\n",
        "        crops = data['Commodity'].unique()\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nTraining model for: {crop}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Filter data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "\n",
        "            # Remove rows with NaN in target\n",
        "            crop_data = crop_data.dropna(subset=[target_col])\n",
        "\n",
        "            if len(crop_data) < 20:\n",
        "                print(f\"  ⚠ Insufficient data for {crop} (only {len(crop_data)} records). Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Prepare features and target\n",
        "            X = crop_data[feature_cols].copy()\n",
        "            y = crop_data[target_col]\n",
        "\n",
        "            # Fill NaN with forward fill then backward fill, then median\n",
        "            X = X.fillna(method='ffill').fillna(method='bfill').fillna(X.median())\n",
        "\n",
        "            # Split data (time-series aware) - use more data for training\n",
        "            split_idx = int(len(X) * 0.85)  # 85/15 split\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            print(f\"  Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            # Train model - using simpler model to reduce overfitting\n",
        "            model = GradientBoostingRegressor(\n",
        "                n_estimators=50,           # Reduced from 200\n",
        "                learning_rate=0.1,         # Increased for faster, simpler learning\n",
        "                max_depth=3,               # Reduced from 5\n",
        "                min_samples_split=10,      # Increased from 5\n",
        "                min_samples_leaf=5,        # Added constraint\n",
        "                subsample=0.8,             # Use 80% of samples per tree\n",
        "                max_features='sqrt',       # Use sqrt of features per split\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred = model.predict(X_train_scaled)\n",
        "            test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            train_mae = mean_absolute_error(y_train, train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, test_pred)\n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "            # Calculate MAPE for better interpretability\n",
        "            train_mape = np.mean(np.abs((y_train - train_pred) / y_train)) * 100\n",
        "            test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
        "\n",
        "            print(f\"  Train MAE: ₹{train_mae:.2f} | R²: {train_r2:.3f} | MAPE: {train_mape:.1f}%\")\n",
        "            print(f\"  Test MAE:  ₹{test_mae:.2f} | R²: {test_r2:.3f} | MAPE: {test_mape:.1f}%\")\n",
        "\n",
        "            # Check for overfitting\n",
        "            if train_r2 > 0.95 and test_r2 < 0.5:\n",
        "                print(f\"  ⚠ WARNING: Severe overfitting detected!\")\n",
        "            elif train_mae < 0.5:\n",
        "                print(f\"  ⚠ WARNING: Training error suspiciously low - possible overfitting\")\n",
        "\n",
        "            # Store model and scaler\n",
        "            self.models[crop] = model\n",
        "            self.scalers[crop] = scaler\n",
        "\n",
        "            results.append({\n",
        "                'Crop': crop,\n",
        "                'Train_MAE': train_mae,\n",
        "                'Test_MAE': test_mae,\n",
        "                'Train_R2': train_r2,\n",
        "                'Test_R2': test_r2,\n",
        "                'Train_MAPE': train_mape,\n",
        "                'Test_MAPE': test_mape,\n",
        "                'Training_Samples': len(X_train),\n",
        "                'Test_Samples': len(X_test),\n",
        "                'Overfitting': 'Yes' if (train_r2 > 0.95 and test_r2 < 0.5) else 'No'\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL TRAINING SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(results_df.to_string(index=False))\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def predict_seasonal_prices(self, df, forecast_year=2026):\n",
        "        \"\"\"\n",
        "        Predict prices for next Kharif and Rabi seasons\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"PREDICTING PRICES FOR YEAR {forecast_year}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        crops = list(self.models.keys())\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nGenerating predictions for: {crop}\")\n",
        "\n",
        "            # Get latest data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "            latest_record = crop_data.iloc[-1]\n",
        "\n",
        "            # Get historical averages for this crop\n",
        "            kharif_avg = crop_data[crop_data['Season'] == 'Kharif']['Price_1KG'].mean()\n",
        "            rabi_avg = crop_data[crop_data['Season'] == 'Rabi']['Price_1KG'].mean()\n",
        "\n",
        "            # Define prediction dates for Kharif and Rabi\n",
        "            seasons = [\n",
        "                {\n",
        "                    'season': 'Kharif',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-07-15'),  # Mid-Kharif\n",
        "                    'month': 7,\n",
        "                    'is_kharif': 1,\n",
        "                    'is_rabi': 0\n",
        "                },\n",
        "                {\n",
        "                    'season': 'Rabi',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-01-15'),  # Mid-Rabi\n",
        "                    'month': 1,\n",
        "                    'is_kharif': 0,\n",
        "                    'is_rabi': 1\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            for season_info in seasons:\n",
        "                # Create feature vector for prediction\n",
        "                pred_features = latest_record[self.feature_columns].copy()\n",
        "\n",
        "                # Update time-based features\n",
        "                pred_features['Month'] = season_info['month']\n",
        "                pred_features['Year'] = forecast_year\n",
        "                pred_features['Is_Kharif'] = season_info['is_kharif']\n",
        "                pred_features['Is_Rabi'] = season_info['is_rabi']\n",
        "                pred_features['Season_Encoded'] = 0 if season_info['season'] == 'Kharif' else 1\n",
        "                pred_features['Month_Sin'] = np.sin(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Month_Cos'] = np.cos(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Quarter'] = (season_info['month'] - 1) // 3 + 1\n",
        "\n",
        "                # Calculate days since start\n",
        "                days_since_start = (season_info['date'] - data['Date'].min()).days\n",
        "                pred_features['Days_Since_Start'] = days_since_start\n",
        "\n",
        "                # Fill any remaining NaN values\n",
        "                pred_features = pred_features.fillna(crop_data[self.feature_columns].median())\n",
        "\n",
        "                # Prepare for prediction\n",
        "                X_pred = pred_features.values.reshape(1, -1)\n",
        "                X_pred_scaled = self.scalers[crop].transform(X_pred)\n",
        "\n",
        "                # Make prediction\n",
        "                predicted_price = self.models[crop].predict(X_pred_scaled)[0]\n",
        "\n",
        "                # Calculate confidence based on historical volatility\n",
        "                historical_std = crop_data['Price_1KG'].std()\n",
        "                confidence_interval = 1.96 * historical_std  # 95% CI\n",
        "\n",
        "                predictions.append({\n",
        "                    'Crop': crop,\n",
        "                    'Season': season_info['season'],\n",
        "                    'Year': forecast_year,\n",
        "                    'Predicted_Price_1KG': round(predicted_price, 2),\n",
        "                    'Lower_Bound': round(predicted_price - confidence_interval, 2),\n",
        "                    'Upper_Bound': round(predicted_price + confidence_interval, 2),\n",
        "                    'Historical_Avg': round(kharif_avg if season_info['season'] == 'Kharif' else rabi_avg, 2),\n",
        "                    'Change_from_Avg': round(predicted_price - (kharif_avg if season_info['season'] == 'Kharif' else rabi_avg), 2)\n",
        "                })\n",
        "\n",
        "        predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASONAL PRICE PREDICTIONS\")\n",
        "        print(\"=\"*80)\n",
        "        print(predictions_df.to_string(index=False))\n",
        "\n",
        "        return predictions_df\n",
        "\n",
        "    def save_models(self, filepath='crop_price_models.pkl'):\n",
        "        \"\"\"\n",
        "        Save trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = {\n",
        "            'models': self.models,\n",
        "            'scalers': self.scalers,\n",
        "            'crop_encoders': self.crop_encoders,\n",
        "            'feature_columns': self.feature_columns\n",
        "        }\n",
        "        joblib.dump(model_data, filepath)\n",
        "        print(f\"\\n✓ Models saved to {filepath}\")\n",
        "\n",
        "    def load_models(self, filepath='crop_price_models_v2.pkl'):\n",
        "        \"\"\"\n",
        "        Load trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = joblib.load(filepath)\n",
        "        self.models = model_data['models']\n",
        "        self.scalers = model_data['scalers']\n",
        "        self.crop_encoders = model_data['crop_encoders']\n",
        "        self.feature_columns = model_data['feature_columns']\n",
        "        print(f\"✓ Models loaded from {filepath}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load processed data\n",
        "    input_files = [\n",
        "        'rice_prices_processed.csv',\n",
        "        'wheat_prices_processed.csv',\n",
        "        'groundnut_prices_processed.csv','jowar_prices_processed.csv','onion_prices_processed.csv','potato_prices_processed.csv',\n",
        "        'ragi_prices_processed.csv','soyabean_prices_processed.csv','tur_prices_processed.csv'\n",
        "        # Add more crop files here\n",
        "    ]\n",
        "\n",
        "    # For demonstration, we'll use rice data\n",
        "    # Replace this with actual loading of all 8 crops\n",
        "    print(\"\\nLoading data...\")\n",
        "\n",
        "    try:\n",
        "        # Load all crop data and combine\n",
        "        all_data = []\n",
        "        for file in input_files:\n",
        "            try:\n",
        "                df = pd.read_csv(file)\n",
        "                all_data.append(df)\n",
        "                print(f\"  ✓ Loaded {file}: {len(df)} records\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"  ⚠ File not found: {file}\")\n",
        "                continue\n",
        "\n",
        "        if not all_data:\n",
        "            print(\"\\n⚠ No data files found. Using sample data...\")\n",
        "            # Load single file for demonstration\n",
        "            df = pd.read_csv('rice_prices_processed.csv')\n",
        "            all_data = [df]\n",
        "\n",
        "        # Combine all crop data\n",
        "        combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "        # Ensure Date column is datetime\n",
        "        if not pd.api.types.is_datetime64_any_dtype(combined_data['Date']):\n",
        "            print(\"\\nConverting Date column to datetime format...\")\n",
        "            try:\n",
        "                combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        print(f\"\\nTotal combined data: {len(combined_data)} records\")\n",
        "        print(f\"Crops in dataset: {combined_data['Commodity'].unique()}\")\n",
        "        print(f\"Date range: {combined_data['Date'].min()} to {combined_data['Date'].max()}\")\n",
        "\n",
        "        # Initialize forecaster\n",
        "        forecaster = CropPriceForecaster()\n",
        "\n",
        "        # Train models\n",
        "        training_results = forecaster.train_models(combined_data)\n",
        "\n",
        "        # Make predictions for next seasons\n",
        "        predictions = forecaster.predict_seasonal_prices(combined_data, forecast_year=2026)\n",
        "\n",
        "        # Save predictions to CSV\n",
        "        predictions.to_csv('seasonal_price_predictions_2026_v2.csv', index=False)\n",
        "        print(\"\\n✓ Predictions saved to 'seasonal_price_predictions_2026_v2.csv'\")\n",
        "\n",
        "        # Save models for future use\n",
        "        forecaster.save_models('crop_price_models.pkl')\n",
        "\n",
        "        # Generate summary report\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREDICTION SUMMARY BY SEASON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for season in ['Kharif', 'Rabi']:\n",
        "            season_data = predictions[predictions['Season'] == season]\n",
        "            print(f\"\\n{season} Season 2026:\")\n",
        "            print(f\"  Average predicted price: ₹{season_data['Predicted_Price_1KG'].mean():.2f}\")\n",
        "            print(f\"  Highest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmax(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].max():.2f}\")\n",
        "            print(f\"  Lowest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmin(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].min():.2f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✓ FORECASTING COMPLETE!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NciBx4wy427",
        "outputId": "a62df205-47dc-4125-9ab8-c892324a57ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\n",
            "================================================================================\n",
            "\n",
            "Loading data...\n",
            "  ✓ Loaded rice_prices_processed.csv: 106 records\n",
            "  ✓ Loaded wheat_prices_processed.csv: 52 records\n",
            "  ✓ Loaded groundnut_prices_processed.csv: 51 records\n",
            "  ✓ Loaded jowar_prices_processed.csv: 67 records\n",
            "  ✓ Loaded onion_prices_processed.csv: 58 records\n",
            "  ✓ Loaded potato_prices_processed.csv: 42 records\n",
            "  ✓ Loaded ragi_prices_processed.csv: 55 records\n",
            "  ✓ Loaded soyabean_prices_processed.csv: 25 records\n",
            "  ✓ Loaded tur_prices_processed.csv: 53 records\n",
            "\n",
            "Converting Date column to datetime format...\n",
            "\n",
            "Total combined data: 509 records\n",
            "Crops in dataset: ['Rice' 'Wheat' 'Groundnut' 'Jowar' 'Onion' 'Potato' 'Ragi' 'Soyabean'\n",
            " 'Tur']\n",
            "Date range: 2022-08-04 00:00:00 to 2025-10-23 00:00:00\n",
            "\n",
            "================================================================================\n",
            "TRAINING MODELS FOR EACH CROP\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "Selected 16 features for modeling\n",
            "Features: ['Commodity_Encoded', 'Season_Encoded', 'Month', 'Year', 'Is_Kharif', 'Is_Rabi', 'Month_Sin', 'Month_Cos', 'Quarter', 'Days_Since_Start', 'Price_1KG_Lag_1', 'Price_1KG_Lag_7', 'Price_1KG_RollingAvg_7', 'Price_Max', 'Price_Min', 'Price_Range']\n",
            "\n",
            "Training model for: Rice\n",
            "--------------------------------------------------\n",
            "  Training samples: 90, Test samples: 16\n",
            "  Train MAE: ₹1.64 | R²: 0.965 | MAPE: 4.3%\n",
            "  Test MAE:  ₹2.19 | R²: 0.911 | MAPE: 6.5%\n",
            "\n",
            "Training model for: Wheat\n",
            "--------------------------------------------------\n",
            "  Training samples: 44, Test samples: 8\n",
            "  Train MAE: ₹0.84 | R²: 0.973 | MAPE: 3.5%\n",
            "  Test MAE:  ₹1.48 | R²: 0.864 | MAPE: 4.3%\n",
            "\n",
            "Training model for: Groundnut\n",
            "--------------------------------------------------\n",
            "  Training samples: 43, Test samples: 8\n",
            "  Train MAE: ₹1.47 | R²: 0.960 | MAPE: 2.9%\n",
            "  Test MAE:  ₹18.50 | R²: -0.746 | MAPE: 22.2%\n",
            "  ⚠ WARNING: Severe overfitting detected!\n",
            "\n",
            "Training model for: Jowar\n",
            "--------------------------------------------------\n",
            "  Training samples: 56, Test samples: 11\n",
            "  Train MAE: ₹0.78 | R²: 0.981 | MAPE: 2.6%\n",
            "  Test MAE:  ₹8.21 | R²: -2.338 | MAPE: 23.9%\n",
            "  ⚠ WARNING: Severe overfitting detected!\n",
            "\n",
            "Training model for: Onion\n",
            "--------------------------------------------------\n",
            "  Training samples: 49, Test samples: 9\n",
            "  Train MAE: ₹2.89 | R²: 0.806 | MAPE: 10.6%\n",
            "  Test MAE:  ₹1.70 | R²: 0.774 | MAPE: 16.5%\n",
            "\n",
            "Training model for: Potato\n",
            "--------------------------------------------------\n",
            "  Training samples: 35, Test samples: 7\n",
            "  Train MAE: ₹0.55 | R²: 0.973 | MAPE: 3.1%\n",
            "  Test MAE:  ₹0.96 | R²: 0.880 | MAPE: 5.3%\n",
            "\n",
            "Training model for: Ragi\n",
            "--------------------------------------------------\n",
            "  Training samples: 46, Test samples: 9\n",
            "  Train MAE: ₹1.16 | R²: 0.913 | MAPE: 3.8%\n",
            "  Test MAE:  ₹8.00 | R²: -2.177 | MAPE: 20.3%\n",
            "\n",
            "Training model for: Soyabean\n",
            "--------------------------------------------------\n",
            "  Training samples: 21, Test samples: 4\n",
            "  Train MAE: ₹1.18 | R²: 0.808 | MAPE: 2.6%\n",
            "  Test MAE:  ₹0.55 | R²: 0.161 | MAPE: 1.4%\n",
            "\n",
            "Training model for: Tur\n",
            "--------------------------------------------------\n",
            "  Training samples: 45, Test samples: 8\n",
            "  Train MAE: ₹2.01 | R²: 0.961 | MAPE: 3.2%\n",
            "  Test MAE:  ₹8.44 | R²: 0.010 | MAPE: 13.5%\n",
            "  ⚠ WARNING: Severe overfitting detected!\n",
            "\n",
            "================================================================================\n",
            "MODEL TRAINING SUMMARY\n",
            "================================================================================\n",
            "     Crop  Train_MAE  Test_MAE  Train_R2   Test_R2  Train_MAPE  Test_MAPE  Training_Samples  Test_Samples Overfitting\n",
            "     Rice   1.635070  2.191325  0.964879  0.910562    4.349802   6.526479                90            16          No\n",
            "    Wheat   0.842560  1.475659  0.973094  0.864475    3.540081   4.341633                44             8          No\n",
            "Groundnut   1.474191 18.495629  0.960186 -0.746197    2.858317  22.168412                43             8         Yes\n",
            "    Jowar   0.781174  8.212603  0.981226 -2.338261    2.617841  23.883635                56            11         Yes\n",
            "    Onion   2.893971  1.704799  0.805643  0.773723   10.581332  16.537838                49             9          No\n",
            "   Potato   0.554004  0.961329  0.973051  0.879717    3.097477   5.323392                35             7          No\n",
            "     Ragi   1.163944  7.995459  0.913019 -2.176754    3.849201  20.338837                46             9          No\n",
            " Soyabean   1.175508  0.545114  0.808109  0.161397    2.637077   1.368634                21             4          No\n",
            "      Tur   2.011723  8.441696  0.960563  0.010045    3.208029  13.526179                45             8         Yes\n",
            "\n",
            "================================================================================\n",
            "PREDICTING PRICES FOR YEAR 2026\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "\n",
            "Generating predictions for: Rice\n",
            "\n",
            "Generating predictions for: Wheat\n",
            "\n",
            "Generating predictions for: Groundnut\n",
            "\n",
            "Generating predictions for: Jowar\n",
            "\n",
            "Generating predictions for: Onion\n",
            "\n",
            "Generating predictions for: Potato\n",
            "\n",
            "Generating predictions for: Ragi\n",
            "\n",
            "Generating predictions for: Soyabean\n",
            "\n",
            "Generating predictions for: Tur\n",
            "\n",
            "================================================================================\n",
            "SEASONAL PRICE PREDICTIONS\n",
            "================================================================================\n",
            "     Crop Season  Year  Predicted_Price_1KG  Lower_Bound  Upper_Bound  Historical_Avg  Change_from_Avg\n",
            "     Rice Kharif  2026                38.96         9.43        68.49           34.38             4.59\n",
            "     Rice   Rabi  2026                40.91        11.38        70.44           42.61            -1.70\n",
            "    Wheat Kharif  2026                39.96        25.66        54.27           31.15             8.81\n",
            "    Wheat   Rabi  2026                40.85        26.55        55.15           29.39            11.46\n",
            "Groundnut Kharif  2026                64.96        36.71        93.22           56.20             8.76\n",
            "Groundnut   Rabi  2026                68.50        40.25        96.75           52.44            16.06\n",
            "    Jowar Kharif  2026                20.84         1.21        40.47           32.23           -11.39\n",
            "    Jowar   Rabi  2026                18.82        -0.81        38.44           26.95            -8.14\n",
            "    Onion Kharif  2026                16.36       -16.02        48.74           20.70            -4.34\n",
            "    Onion   Rabi  2026                14.49       -17.89        46.87           21.38            -6.89\n",
            "   Potato Kharif  2026                17.57         8.71        26.43           19.12            -1.55\n",
            "   Potato   Rabi  2026                16.65         7.79        25.51           19.17            -2.52\n",
            "     Ragi Kharif  2026                27.44        15.18        39.69           31.83            -4.39\n",
            "     Ragi   Rabi  2026                28.57        16.32        40.82           31.01            -2.45\n",
            " Soyabean Kharif  2026                41.09        31.37        50.80           42.22            -1.13\n",
            " Soyabean   Rabi  2026                42.03        32.31        51.74           41.90             0.12\n",
            "      Tur Kharif  2026                77.92        46.79       109.05           65.68            12.24\n",
            "      Tur   Rabi  2026                74.52        43.38       105.65           68.62             5.89\n",
            "\n",
            "✓ Predictions saved to 'seasonal_price_predictions_2026_v2.csv'\n",
            "\n",
            "✓ Models saved to crop_price_models.pkl\n",
            "\n",
            "================================================================================\n",
            "PREDICTION SUMMARY BY SEASON\n",
            "================================================================================\n",
            "\n",
            "Kharif Season 2026:\n",
            "  Average predicted price: ₹38.34\n",
            "  Highest: Tur - ₹77.92\n",
            "  Lowest: Onion - ₹16.36\n",
            "\n",
            "Rabi Season 2026:\n",
            "  Average predicted price: ₹38.37\n",
            "  Highest: Tur - ₹74.52\n",
            "  Lowest: Onion - ₹14.49\n",
            "\n",
            "================================================================================\n",
            "✓ FORECASTING COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CropPriceForecaster:\n",
        "    \"\"\"\n",
        "    Multi-crop price forecasting system for seasonal predictions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self.crop_encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"\n",
        "        Prepare data for modeling\n",
        "        \"\"\"\n",
        "        print(\"Preparing data for modeling...\")\n",
        "\n",
        "        # Create a copy\n",
        "        data = df.copy()\n",
        "\n",
        "        # Convert Date to datetime if it's not already\n",
        "        if not pd.api.types.is_datetime64_any_dtype(data['Date']):\n",
        "            print(\"  Converting Date column to datetime...\")\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    data['Date'] = pd.to_datetime(data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le_commodity = LabelEncoder()\n",
        "        data['Commodity_Encoded'] = le_commodity.fit_transform(data['Commodity'])\n",
        "\n",
        "        le_season = LabelEncoder()\n",
        "        data['Season_Encoded'] = le_season.fit_transform(data['Season'])\n",
        "\n",
        "        # Store encoders\n",
        "        self.crop_encoders['commodity'] = le_commodity\n",
        "        self.crop_encoders['season'] = le_season\n",
        "\n",
        "        # Create additional features\n",
        "        data['Days_Since_Start'] = (data['Date'] - data['Date'].min()).dt.days\n",
        "\n",
        "        # Seasonal indicators\n",
        "        data['Is_Kharif'] = (data['Season'] == 'Kharif').astype(int)\n",
        "        data['Is_Rabi'] = (data['Season'] == 'Rabi').astype(int)\n",
        "\n",
        "        # Cyclical time features (sine/cosine for month)\n",
        "        data['Month_Sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
        "        data['Month_Cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def select_features(self, data):\n",
        "        \"\"\"\n",
        "        Select relevant features for modeling - simplified to reduce overfitting\n",
        "        \"\"\"\n",
        "        # Use only the most important features to avoid overfitting\n",
        "        important_features = [\n",
        "            'Commodity_Encoded',\n",
        "            'Season_Encoded',\n",
        "            'Month',\n",
        "            'Year',\n",
        "            'Is_Kharif',\n",
        "            'Is_Rabi',\n",
        "            'Month_Sin',\n",
        "            'Month_Cos',\n",
        "            'Quarter',\n",
        "            'Days_Since_Start',\n",
        "            'Price_1KG_Lag_1',\n",
        "            'Price_1KG_Lag_7',\n",
        "            'Price_1KG_RollingAvg_7',\n",
        "            'Price_Max',\n",
        "            'Price_Min',\n",
        "            'Price_Range'\n",
        "        ]\n",
        "\n",
        "        # Only keep features that exist in the data\n",
        "        feature_cols = [col for col in important_features if col in data.columns]\n",
        "\n",
        "        # Remove columns with too many NaN values (>30%)\n",
        "        feature_cols = [col for col in feature_cols if data[col].isna().sum() / len(data) < 0.3]\n",
        "\n",
        "        self.feature_columns = feature_cols\n",
        "        print(f\"Selected {len(feature_cols)} features for modeling\")\n",
        "        print(f\"Features: {feature_cols}\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def train_models(self, df, target_col='Price_1KG', use_unified_model=True):\n",
        "        \"\"\"\n",
        "        Train models - can use either separate models per crop or one unified model\n",
        "\n",
        "        Args:\n",
        "            use_unified_model: If True, trains one model for all crops (better for small datasets)\n",
        "                              If False, trains separate models per crop\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        if use_unified_model:\n",
        "            print(\"TRAINING UNIFIED MODEL FOR ALL CROPS (Recommended for small datasets)\")\n",
        "        else:\n",
        "            print(\"TRAINING SEPARATE MODELS FOR EACH CROP\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        feature_cols = self.select_features(data)\n",
        "\n",
        "        # Get unique crops\n",
        "        crops = data['Commodity'].unique()\n",
        "\n",
        "        if use_unified_model:\n",
        "            return self._train_unified_model(data, crops, feature_cols, target_col)\n",
        "        else:\n",
        "            return self._train_separate_models(data, crops, feature_cols, target_col)\n",
        "\n",
        "    def _train_unified_model(self, data, crops, feature_cols, target_col):\n",
        "        \"\"\"\n",
        "        Train one model for all crops together\n",
        "        \"\"\"\n",
        "        print(f\"\\nTraining unified model on {len(data)} total samples...\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Remove rows with NaN in target\n",
        "        data = data.dropna(subset=[target_col])\n",
        "\n",
        "        # Prepare features and target\n",
        "        X = data[feature_cols].copy()\n",
        "        y = data[target_col]\n",
        "\n",
        "        # Fill NaN\n",
        "        X = X.fillna(method='ffill').fillna(method='bfill').fillna(X.median())\n",
        "\n",
        "        # Split data (time-series aware)\n",
        "        split_idx = int(len(X) * 0.85)\n",
        "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        # Keep track of which crop each sample belongs to for evaluation\n",
        "        crop_train = data['Commodity'][:split_idx]\n",
        "        crop_test = data['Commodity'][split_idx:]\n",
        "\n",
        "        print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train unified model\n",
        "        model = GradientBoostingRegressor(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.08,\n",
        "            max_depth=4,\n",
        "            min_samples_split=15,\n",
        "            min_samples_leaf=8,\n",
        "            subsample=0.8,\n",
        "            max_features='sqrt',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        train_pred = model.predict(X_train_scaled)\n",
        "        test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        train_mae = mean_absolute_error(y_train, train_pred)\n",
        "        test_mae = mean_absolute_error(y_test, test_pred)\n",
        "        train_r2 = r2_score(y_train, train_pred)\n",
        "        test_r2 = r2_score(y_test, test_pred)\n",
        "        train_mape = np.mean(np.abs((y_train - train_pred) / y_train)) * 100\n",
        "        test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
        "\n",
        "        print(f\"\\nOverall Performance:\")\n",
        "        print(f\"  Train MAE: ₹{train_mae:.2f} | R²: {train_r2:.3f} | MAPE: {train_mape:.1f}%\")\n",
        "        print(f\"  Test MAE:  ₹{test_mae:.2f} | R²: {test_r2:.3f} | MAPE: {test_mape:.1f}%\")\n",
        "\n",
        "        # Store unified model for all crops\n",
        "        for crop in crops:\n",
        "            self.models[crop] = model\n",
        "            self.scalers[crop] = scaler\n",
        "\n",
        "        # Evaluate per crop on test set\n",
        "        print(f\"\\nPer-Crop Test Performance:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        results = []\n",
        "        for crop in crops:\n",
        "            crop_mask = crop_test == crop\n",
        "            if crop_mask.sum() > 0:\n",
        "                crop_y_test = y_test[crop_mask]\n",
        "                crop_pred = test_pred[crop_mask]\n",
        "\n",
        "                crop_mae = mean_absolute_error(crop_y_test, crop_pred)\n",
        "                crop_r2 = r2_score(crop_y_test, crop_pred) if len(crop_y_test) > 1 else 0\n",
        "                crop_mape = np.mean(np.abs((crop_y_test - crop_pred) / crop_y_test)) * 100\n",
        "\n",
        "                print(f\"  {crop:15s} - MAE: ₹{crop_mae:6.2f} | R²: {crop_r2:6.3f} | MAPE: {crop_mape:5.1f}% | Samples: {crop_mask.sum()}\")\n",
        "\n",
        "                results.append({\n",
        "                    'Crop': crop,\n",
        "                    'Test_MAE': crop_mae,\n",
        "                    'Test_R2': crop_r2,\n",
        "                    'Test_MAPE': crop_mape,\n",
        "                    'Test_Samples': crop_mask.sum(),\n",
        "                    'Model_Type': 'Unified'\n",
        "                })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        return results_df\n",
        "\n",
        "    def _train_separate_models(self, data, crops, feature_cols, target_col):\n",
        "        \"\"\"\n",
        "        Train separate models for each crop (original approach)\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nTraining model for: {crop}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Filter data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "\n",
        "            # Remove rows with NaN in target\n",
        "            crop_data = crop_data.dropna(subset=[target_col])\n",
        "\n",
        "            if len(crop_data) < 20:\n",
        "                print(f\"  ⚠ Insufficient data for {crop} (only {len(crop_data)} records). Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Prepare features and target\n",
        "            X = crop_data[feature_cols].copy()\n",
        "            y = crop_data[target_col]\n",
        "\n",
        "            # Fill NaN with forward fill then backward fill, then median\n",
        "            X = X.fillna(method='ffill').fillna(method='bfill').fillna(X.median())\n",
        "\n",
        "            # Split data (time-series aware) - use more data for training\n",
        "            split_idx = int(len(X) * 0.85)  # 85/15 split\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            print(f\"  Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            # Train model - using simpler model to reduce overfitting\n",
        "            model = GradientBoostingRegressor(\n",
        "                n_estimators=50,           # Reduced from 200\n",
        "                learning_rate=0.1,         # Increased for faster, simpler learning\n",
        "                max_depth=3,               # Reduced from 5\n",
        "                min_samples_split=10,      # Increased from 5\n",
        "                min_samples_leaf=5,        # Added constraint\n",
        "                subsample=0.8,             # Use 80% of samples per tree\n",
        "                max_features='sqrt',       # Use sqrt of features per split\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred = model.predict(X_train_scaled)\n",
        "            test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            train_mae = mean_absolute_error(y_train, train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, test_pred)\n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "            # Calculate MAPE for better interpretability\n",
        "            train_mape = np.mean(np.abs((y_train - train_pred) / y_train)) * 100\n",
        "            test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
        "\n",
        "            print(f\"  Train MAE: ₹{train_mae:.2f} | R²: {train_r2:.3f} | MAPE: {train_mape:.1f}%\")\n",
        "            print(f\"  Test MAE:  ₹{test_mae:.2f} | R²: {test_r2:.3f} | MAPE: {test_mape:.1f}%\")\n",
        "\n",
        "            # Check for overfitting\n",
        "            if train_r2 > 0.95 and test_r2 < 0.5:\n",
        "                print(f\"  ⚠ WARNING: Severe overfitting detected!\")\n",
        "            elif train_mae < 0.5:\n",
        "                print(f\"  ⚠ WARNING: Training error suspiciously low - possible overfitting\")\n",
        "\n",
        "            # Store model and scaler\n",
        "            self.models[crop] = model\n",
        "            self.scalers[crop] = scaler\n",
        "\n",
        "            results.append({\n",
        "                'Crop': crop,\n",
        "                'Train_MAE': train_mae,\n",
        "                'Test_MAE': test_mae,\n",
        "                'Train_R2': train_r2,\n",
        "                'Test_R2': test_r2,\n",
        "                'Train_MAPE': train_mape,\n",
        "                'Test_MAPE': test_mape,\n",
        "                'Training_Samples': len(X_train),\n",
        "                'Test_Samples': len(X_test),\n",
        "                'Overfitting': 'Yes' if (train_r2 > 0.95 and test_r2 < 0.5) else 'No'\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL TRAINING SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(results_df.to_string(index=False))\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def predict_seasonal_prices(self, df, forecast_year=2026):\n",
        "        \"\"\"\n",
        "        Predict prices for next Kharif and Rabi seasons\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"PREDICTING PRICES FOR YEAR {forecast_year}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        data = self.prepare_data(df)\n",
        "        crops = list(self.models.keys())\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for crop in crops:\n",
        "            print(f\"\\nGenerating predictions for: {crop}\")\n",
        "\n",
        "            # Get latest data for this crop\n",
        "            crop_data = data[data['Commodity'] == crop].copy()\n",
        "            latest_record = crop_data.iloc[-1]\n",
        "\n",
        "            # Get historical averages for this crop\n",
        "            kharif_avg = crop_data[crop_data['Season'] == 'Kharif']['Price_1KG'].mean()\n",
        "            rabi_avg = crop_data[crop_data['Season'] == 'Rabi']['Price_1KG'].mean()\n",
        "\n",
        "            # Define prediction dates for Kharif and Rabi\n",
        "            seasons = [\n",
        "                {\n",
        "                    'season': 'Kharif',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-07-15'),  # Mid-Kharif\n",
        "                    'month': 7,\n",
        "                    'is_kharif': 1,\n",
        "                    'is_rabi': 0\n",
        "                },\n",
        "                {\n",
        "                    'season': 'Rabi',\n",
        "                    'date': pd.Timestamp(f'{forecast_year}-01-15'),  # Mid-Rabi\n",
        "                    'month': 1,\n",
        "                    'is_kharif': 0,\n",
        "                    'is_rabi': 1\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            for season_info in seasons:\n",
        "                # Create feature vector for prediction\n",
        "                pred_features = latest_record[self.feature_columns].copy()\n",
        "\n",
        "                # Update time-based features\n",
        "                pred_features['Month'] = season_info['month']\n",
        "                pred_features['Year'] = forecast_year\n",
        "                pred_features['Is_Kharif'] = season_info['is_kharif']\n",
        "                pred_features['Is_Rabi'] = season_info['is_rabi']\n",
        "                pred_features['Season_Encoded'] = 0 if season_info['season'] == 'Kharif' else 1\n",
        "                pred_features['Month_Sin'] = np.sin(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Month_Cos'] = np.cos(2 * np.pi * season_info['month'] / 12)\n",
        "                pred_features['Quarter'] = (season_info['month'] - 1) // 3 + 1\n",
        "\n",
        "                # Calculate days since start\n",
        "                days_since_start = (season_info['date'] - data['Date'].min()).days\n",
        "                pred_features['Days_Since_Start'] = days_since_start\n",
        "\n",
        "                # Fill any remaining NaN values\n",
        "                pred_features = pred_features.fillna(crop_data[self.feature_columns].median())\n",
        "\n",
        "                # Prepare for prediction\n",
        "                X_pred = pred_features.values.reshape(1, -1)\n",
        "                X_pred_scaled = self.scalers[crop].transform(X_pred)\n",
        "\n",
        "                # Make prediction\n",
        "                predicted_price = self.models[crop].predict(X_pred_scaled)[0]\n",
        "\n",
        "                # Calculate confidence based on historical volatility\n",
        "                historical_std = crop_data['Price_1KG'].std()\n",
        "                confidence_interval = 1.96 * historical_std  # 95% CI\n",
        "\n",
        "                predictions.append({\n",
        "                    'Crop': crop,\n",
        "                    'Season': season_info['season'],\n",
        "                    'Year': forecast_year,\n",
        "                    'Predicted_Price_1KG': round(predicted_price, 2),\n",
        "                    'Lower_Bound': round(predicted_price - confidence_interval, 2),\n",
        "                    'Upper_Bound': round(predicted_price + confidence_interval, 2),\n",
        "                    'Historical_Avg': round(kharif_avg if season_info['season'] == 'Kharif' else rabi_avg, 2),\n",
        "                    'Change_from_Avg': round(predicted_price - (kharif_avg if season_info['season'] == 'Kharif' else rabi_avg), 2)\n",
        "                })\n",
        "\n",
        "        predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SEASONAL PRICE PREDICTIONS\")\n",
        "        print(\"=\"*80)\n",
        "        print(predictions_df.to_string(index=False))\n",
        "\n",
        "        return predictions_df\n",
        "\n",
        "    def save_models(self, filepath='crop.pkl'):\n",
        "        \"\"\"\n",
        "        Save trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = {\n",
        "            'models': self.models,\n",
        "            'scalers': self.scalers,\n",
        "            'crop_encoders': self.crop_encoders,\n",
        "            'feature_columns': self.feature_columns\n",
        "        }\n",
        "        joblib.dump(model_data, filepath)\n",
        "        print(f\"\\n✓ Models saved to {filepath}\")\n",
        "\n",
        "    def load_models(self, filepath='crop.pkl'):\n",
        "        \"\"\"\n",
        "        Load trained models and scalers\n",
        "        \"\"\"\n",
        "        model_data = joblib.load(filepath)\n",
        "        self.models = model_data['models']\n",
        "        self.scalers = model_data['scalers']\n",
        "        self.crop_encoders = model_data['crop_encoders']\n",
        "        self.feature_columns = model_data['feature_columns']\n",
        "        print(f\"✓ Models loaded from {filepath}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load processed data\n",
        "    input_files = [\n",
        "        'rice_prices_processed.csv',\n",
        "        'wheat_prices_processed.csv',\n",
        "        'groundnut_prices_processed.csv','jowar_prices_processed.csv','onion_prices_processed.csv','potato_prices_processed.csv',\n",
        "        'ragi_prices_processed.csv','soyabean_prices_processed.csv','tur_prices_processed.csv'\n",
        "        # Add more crop files here\n",
        "    ]\n",
        "\n",
        "    # For demonstration, we'll use rice data\n",
        "    # Replace this with actual loading of all 8 crops\n",
        "    print(\"\\nLoading data...\")\n",
        "\n",
        "    try:\n",
        "        # Load all crop data and combine\n",
        "        all_data = []\n",
        "        for file in input_files:\n",
        "            try:\n",
        "                df = pd.read_csv(file)\n",
        "                all_data.append(df)\n",
        "                print(f\"  ✓ Loaded {file}: {len(df)} records\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"  ⚠ File not found: {file}\")\n",
        "                continue\n",
        "\n",
        "        if not all_data:\n",
        "            print(\"\\n⚠ No data files found. Using sample data...\")\n",
        "            # Load single file for demonstration\n",
        "            df = pd.read_csv('rice_prices_processed.csv')\n",
        "            all_data = [df]\n",
        "\n",
        "        # Combine all crop data\n",
        "        combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "        # Ensure Date column is datetime\n",
        "        if not pd.api.types.is_datetime64_any_dtype(combined_data['Date']):\n",
        "            print(\"\\nConverting Date column to datetime format...\")\n",
        "            try:\n",
        "                combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%d/%m/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%Y-%m-%d')\n",
        "                except:\n",
        "                    combined_data['Date'] = pd.to_datetime(combined_data['Date'], infer_datetime_format=True)\n",
        "\n",
        "        print(f\"\\nTotal combined data: {len(combined_data)} records\")\n",
        "        print(f\"Crops in dataset: {combined_data['Commodity'].unique()}\")\n",
        "        print(f\"Date range: {combined_data['Date'].min()} to {combined_data['Date'].max()}\")\n",
        "\n",
        "        # Initialize forecaster\n",
        "        forecaster = CropPriceForecaster()\n",
        "\n",
        "        # Train models - use unified model for better generalization\n",
        "        print(\"\\nChoose training approach:\")\n",
        "        print(\"1. Unified Model (ONE model for all crops - recommended for small datasets)\")\n",
        "        print(\"2. Separate Models (individual model per crop - needs more data)\")\n",
        "\n",
        "        # Default to unified model (better for small datasets)\n",
        "        use_unified = True  # Change to False for separate models\n",
        "\n",
        "        training_results = forecaster.train_models(combined_data, use_unified_model=use_unified)\n",
        "\n",
        "        # Make predictions for next seasons\n",
        "        predictions = forecaster.predict_seasonal_prices(combined_data, forecast_year=2026)\n",
        "\n",
        "        # Save predictions to CSV\n",
        "        predictions.to_csv('seasonal_price_predictions_2026_v3.csv', index=False)\n",
        "        print(\"\\n✓ Predictions saved to 'seasonal_price_predictions_2026.csv'\")\n",
        "\n",
        "        # Save models for future use\n",
        "        forecaster.save_models('crop_price_models.pkl')\n",
        "\n",
        "        # Generate summary report\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PREDICTION SUMMARY BY SEASON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for season in ['Kharif', 'Rabi']:\n",
        "            season_data = predictions[predictions['Season'] == season]\n",
        "            print(f\"\\n{season} Season 2026:\")\n",
        "            print(f\"  Average predicted price: ₹{season_data['Predicted_Price_1KG'].mean():.2f}\")\n",
        "            print(f\"  Highest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmax(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].max():.2f}\")\n",
        "            print(f\"  Lowest: {season_data.loc[season_data['Predicted_Price_1KG'].idxmin(), 'Crop']} - ₹{season_data['Predicted_Price_1KG'].min():.2f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✓ FORECASTING COMPLETE!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmp0FVgHzYvg",
        "outputId": "5c79a30f-5aae-4205-c762-75d38ff5532e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CROP SEASONAL PRICE FORECASTING SYSTEM\n",
            "================================================================================\n",
            "\n",
            "Loading data...\n",
            "  ✓ Loaded rice_prices_processed.csv: 106 records\n",
            "  ✓ Loaded wheat_prices_processed.csv: 52 records\n",
            "  ✓ Loaded groundnut_prices_processed.csv: 51 records\n",
            "  ✓ Loaded jowar_prices_processed.csv: 67 records\n",
            "  ✓ Loaded onion_prices_processed.csv: 58 records\n",
            "  ✓ Loaded potato_prices_processed.csv: 42 records\n",
            "  ✓ Loaded ragi_prices_processed.csv: 55 records\n",
            "  ✓ Loaded soyabean_prices_processed.csv: 25 records\n",
            "  ✓ Loaded tur_prices_processed.csv: 53 records\n",
            "\n",
            "Converting Date column to datetime format...\n",
            "\n",
            "Total combined data: 509 records\n",
            "Crops in dataset: ['Rice' 'Wheat' 'Groundnut' 'Jowar' 'Onion' 'Potato' 'Ragi' 'Soyabean'\n",
            " 'Tur']\n",
            "Date range: 2022-08-04 00:00:00 to 2025-10-23 00:00:00\n",
            "\n",
            "Choose training approach:\n",
            "1. Unified Model (ONE model for all crops - recommended for small datasets)\n",
            "2. Separate Models (individual model per crop - needs more data)\n",
            "\n",
            "================================================================================\n",
            "TRAINING UNIFIED MODEL FOR ALL CROPS (Recommended for small datasets)\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "Selected 16 features for modeling\n",
            "Features: ['Commodity_Encoded', 'Season_Encoded', 'Month', 'Year', 'Is_Kharif', 'Is_Rabi', 'Month_Sin', 'Month_Cos', 'Quarter', 'Days_Since_Start', 'Price_1KG_Lag_1', 'Price_1KG_Lag_7', 'Price_1KG_RollingAvg_7', 'Price_Max', 'Price_Min', 'Price_Range']\n",
            "\n",
            "Training unified model on 509 total samples...\n",
            "--------------------------------------------------\n",
            "Training samples: 432, Test samples: 77\n",
            "\n",
            "Overall Performance:\n",
            "  Train MAE: ₹1.38 | R²: 0.968 | MAPE: 4.7%\n",
            "  Test MAE:  ₹4.69 | R²: 0.838 | MAPE: 7.0%\n",
            "\n",
            "Per-Crop Test Performance:\n",
            "--------------------------------------------------\n",
            "  Soyabean        - MAE: ₹  1.86 | R²:  0.733 | MAPE:   4.6% | Samples: 24\n",
            "  Tur             - MAE: ₹  5.98 | R²:  0.704 | MAPE:   8.1% | Samples: 53\n",
            "\n",
            "================================================================================\n",
            "PREDICTING PRICES FOR YEAR 2026\n",
            "================================================================================\n",
            "Preparing data for modeling...\n",
            "\n",
            "Generating predictions for: Rice\n",
            "\n",
            "Generating predictions for: Wheat\n",
            "\n",
            "Generating predictions for: Groundnut\n",
            "\n",
            "Generating predictions for: Jowar\n",
            "\n",
            "Generating predictions for: Onion\n",
            "\n",
            "Generating predictions for: Potato\n",
            "\n",
            "Generating predictions for: Ragi\n",
            "\n",
            "Generating predictions for: Soyabean\n",
            "\n",
            "Generating predictions for: Tur\n",
            "\n",
            "================================================================================\n",
            "SEASONAL PRICE PREDICTIONS\n",
            "================================================================================\n",
            "     Crop Season  Year  Predicted_Price_1KG  Lower_Bound  Upper_Bound  Historical_Avg  Change_from_Avg\n",
            "     Rice Kharif  2026                39.98        10.45        69.51           34.38             5.61\n",
            "     Rice   Rabi  2026                41.26        11.73        70.79           42.61            -1.35\n",
            "    Wheat Kharif  2026                36.77        22.47        51.07           31.15             5.62\n",
            "    Wheat   Rabi  2026                37.68        23.38        51.98           29.39             8.29\n",
            "Groundnut Kharif  2026                61.06        32.81        89.31           56.20             4.86\n",
            "Groundnut   Rabi  2026                64.37        36.12        92.62           52.44            11.93\n",
            "    Jowar Kharif  2026                38.73        19.11        58.36           32.23             6.51\n",
            "    Jowar   Rabi  2026                38.90        19.28        58.53           26.95            11.95\n",
            "    Onion Kharif  2026                13.55       -18.83        45.93           20.70            -7.15\n",
            "    Onion   Rabi  2026                14.07       -18.30        46.45           21.38            -7.31\n",
            "   Potato Kharif  2026                16.70         7.84        25.56           19.12            -2.42\n",
            "   Potato   Rabi  2026                16.97         8.11        25.83           19.17            -2.20\n",
            "     Ragi Kharif  2026                40.20        27.94        52.45           31.83             8.36\n",
            "     Ragi   Rabi  2026                40.81        28.56        53.06           31.01             9.80\n",
            " Soyabean Kharif  2026                39.97        30.26        49.69           42.22            -2.24\n",
            " Soyabean   Rabi  2026                40.69        30.97        50.40           41.90            -1.22\n",
            "      Tur Kharif  2026                71.95        40.82       103.08           65.68             6.27\n",
            "      Tur   Rabi  2026                71.88        40.75       103.01           68.62             3.26\n",
            "\n",
            "✓ Predictions saved to 'seasonal_price_predictions_2026.csv'\n",
            "\n",
            "✓ Models saved to crop_price_models.pkl\n",
            "\n",
            "================================================================================\n",
            "PREDICTION SUMMARY BY SEASON\n",
            "================================================================================\n",
            "\n",
            "Kharif Season 2026:\n",
            "  Average predicted price: ₹39.88\n",
            "  Highest: Tur - ₹71.95\n",
            "  Lowest: Onion - ₹13.55\n",
            "\n",
            "Rabi Season 2026:\n",
            "  Average predicted price: ₹40.74\n",
            "  Highest: Tur - ₹71.88\n",
            "  Lowest: Onion - ₹14.07\n",
            "\n",
            "================================================================================\n",
            "✓ FORECASTING COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}